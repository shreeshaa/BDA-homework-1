{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/1000\n",
      "80/80 [==============================] - 0s 3ms/sample - loss: 2.3133 - acc: 0.0750 - val_loss: 2.3160 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "80/80 [==============================] - 0s 212us/sample - loss: 2.3024 - acc: 0.1625 - val_loss: 2.3112 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "80/80 [==============================] - 0s 251us/sample - loss: 2.2957 - acc: 0.1625 - val_loss: 2.3058 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "80/80 [==============================] - 0s 246us/sample - loss: 2.2915 - acc: 0.1625 - val_loss: 2.3012 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "80/80 [==============================] - 0s 238us/sample - loss: 2.2871 - acc: 0.1500 - val_loss: 2.2968 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "80/80 [==============================] - 0s 262us/sample - loss: 2.2813 - acc: 0.1500 - val_loss: 2.2962 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "80/80 [==============================] - 0s 265us/sample - loss: 2.2760 - acc: 0.1125 - val_loss: 2.2906 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "80/80 [==============================] - 0s 506us/sample - loss: 2.2716 - acc: 0.1250 - val_loss: 2.2872 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "80/80 [==============================] - 0s 520us/sample - loss: 2.2698 - acc: 0.0750 - val_loss: 2.2859 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "80/80 [==============================] - 0s 542us/sample - loss: 2.2635 - acc: 0.0750 - val_loss: 2.2877 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "80/80 [==============================] - 0s 532us/sample - loss: 2.2553 - acc: 0.0875 - val_loss: 2.2808 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "80/80 [==============================] - 0s 552us/sample - loss: 2.2502 - acc: 0.0750 - val_loss: 2.2891 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 2.2448 - acc: 0.1000 - val_loss: 2.2875 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "80/80 [==============================] - 0s 478us/sample - loss: 2.2390 - acc: 0.0875 - val_loss: 2.2828 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "80/80 [==============================] - 0s 413us/sample - loss: 2.2345 - acc: 0.0750 - val_loss: 2.2784 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "80/80 [==============================] - 0s 447us/sample - loss: 2.2305 - acc: 0.0875 - val_loss: 2.2834 - val_acc: 0.0500\n",
      "Epoch 17/1000\n",
      "80/80 [==============================] - 0s 441us/sample - loss: 2.2277 - acc: 0.0750 - val_loss: 2.2771 - val_acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 2.2211 - acc: 0.0750 - val_loss: 2.2742 - val_acc: 0.0500\n",
      "Epoch 19/1000\n",
      "80/80 [==============================] - 0s 502us/sample - loss: 2.2158 - acc: 0.0750 - val_loss: 2.2753 - val_acc: 0.0500\n",
      "Epoch 20/1000\n",
      "80/80 [==============================] - 0s 468us/sample - loss: 2.2118 - acc: 0.0750 - val_loss: 2.2698 - val_acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "80/80 [==============================] - 0s 487us/sample - loss: 2.2083 - acc: 0.0750 - val_loss: 2.2696 - val_acc: 0.0500\n",
      "Epoch 22/1000\n",
      "80/80 [==============================] - 0s 439us/sample - loss: 2.2024 - acc: 0.0750 - val_loss: 2.2710 - val_acc: 0.0500\n",
      "Epoch 23/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 2.1978 - acc: 0.0750 - val_loss: 2.2634 - val_acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "80/80 [==============================] - 0s 382us/sample - loss: 2.1920 - acc: 0.0625 - val_loss: 2.2644 - val_acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "80/80 [==============================] - 0s 447us/sample - loss: 2.1877 - acc: 0.0625 - val_loss: 2.2654 - val_acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "80/80 [==============================] - 0s 406us/sample - loss: 2.1820 - acc: 0.0500 - val_loss: 2.2616 - val_acc: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "80/80 [==============================] - 0s 410us/sample - loss: 2.1760 - acc: 0.0500 - val_loss: 2.2567 - val_acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "80/80 [==============================] - 0s 419us/sample - loss: 2.1705 - acc: 0.0875 - val_loss: 2.2517 - val_acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "80/80 [==============================] - 0s 492us/sample - loss: 2.1664 - acc: 0.1000 - val_loss: 2.2563 - val_acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "80/80 [==============================] - 0s 434us/sample - loss: 2.1571 - acc: 0.0875 - val_loss: 2.2425 - val_acc: 0.0500\n",
      "Epoch 31/1000\n",
      "80/80 [==============================] - 0s 504us/sample - loss: 2.1564 - acc: 0.1000 - val_loss: 2.2401 - val_acc: 0.0500\n",
      "Epoch 32/1000\n",
      "80/80 [==============================] - 0s 503us/sample - loss: 2.1484 - acc: 0.1000 - val_loss: 2.2451 - val_acc: 0.0500\n",
      "Epoch 33/1000\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 2.1431 - acc: 0.1000 - val_loss: 2.2389 - val_acc: 0.0500\n",
      "Epoch 34/1000\n",
      "80/80 [==============================] - 0s 444us/sample - loss: 2.1376 - acc: 0.1125 - val_loss: 2.2529 - val_acc: 0.0500\n",
      "Epoch 35/1000\n",
      "80/80 [==============================] - 0s 464us/sample - loss: 2.1334 - acc: 0.1125 - val_loss: 2.2268 - val_acc: 0.1000\n",
      "Epoch 36/1000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 2.1293 - acc: 0.1000 - val_loss: 2.2253 - val_acc: 0.1000\n",
      "Epoch 37/1000\n",
      "80/80 [==============================] - 0s 450us/sample - loss: 2.1214 - acc: 0.1375 - val_loss: 2.2239 - val_acc: 0.1000\n",
      "Epoch 38/1000\n",
      "80/80 [==============================] - 0s 439us/sample - loss: 2.1179 - acc: 0.1250 - val_loss: 2.2224 - val_acc: 0.0500\n",
      "Epoch 39/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 2.1139 - acc: 0.1375 - val_loss: 2.2293 - val_acc: 0.0500\n",
      "Epoch 40/1000\n",
      "80/80 [==============================] - 0s 469us/sample - loss: 2.1103 - acc: 0.1375 - val_loss: 2.2203 - val_acc: 0.0500\n",
      "Epoch 41/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 2.1048 - acc: 0.1500 - val_loss: 2.2140 - val_acc: 0.1000\n",
      "Epoch 42/1000\n",
      "80/80 [==============================] - 0s 460us/sample - loss: 2.0996 - acc: 0.1375 - val_loss: 2.2238 - val_acc: 0.1000\n",
      "Epoch 43/1000\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 2.0992 - acc: 0.1375 - val_loss: 2.2102 - val_acc: 0.1000\n",
      "Epoch 44/1000\n",
      "80/80 [==============================] - 0s 406us/sample - loss: 2.0927 - acc: 0.1500 - val_loss: 2.2064 - val_acc: 0.0500\n",
      "Epoch 45/1000\n",
      "80/80 [==============================] - 0s 435us/sample - loss: 2.0894 - acc: 0.1500 - val_loss: 2.2078 - val_acc: 0.1000\n",
      "Epoch 46/1000\n",
      "80/80 [==============================] - 0s 433us/sample - loss: 2.0851 - acc: 0.2250 - val_loss: 2.2096 - val_acc: 0.1000\n",
      "Epoch 47/1000\n",
      "80/80 [==============================] - 0s 500us/sample - loss: 2.0855 - acc: 0.2250 - val_loss: 2.2015 - val_acc: 0.1000\n",
      "Epoch 48/1000\n",
      "80/80 [==============================] - 0s 472us/sample - loss: 2.0772 - acc: 0.2750 - val_loss: 2.2023 - val_acc: 0.1500\n",
      "Epoch 49/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 2.0712 - acc: 0.2750 - val_loss: 2.1997 - val_acc: 0.1000\n",
      "Epoch 50/1000\n",
      "80/80 [==============================] - 0s 458us/sample - loss: 2.0683 - acc: 0.2875 - val_loss: 2.1981 - val_acc: 0.1000\n",
      "Epoch 51/1000\n",
      "80/80 [==============================] - 0s 506us/sample - loss: 2.0656 - acc: 0.2750 - val_loss: 2.1921 - val_acc: 0.1000\n",
      "Epoch 52/1000\n",
      "80/80 [==============================] - 0s 489us/sample - loss: 2.0605 - acc: 0.2875 - val_loss: 2.1936 - val_acc: 0.1000\n",
      "Epoch 53/1000\n",
      "80/80 [==============================] - 0s 472us/sample - loss: 2.0572 - acc: 0.2750 - val_loss: 2.1914 - val_acc: 0.1000\n",
      "Epoch 54/1000\n",
      "80/80 [==============================] - 0s 469us/sample - loss: 2.0507 - acc: 0.2875 - val_loss: 2.1929 - val_acc: 0.1000\n",
      "Epoch 55/1000\n",
      "80/80 [==============================] - 0s 531us/sample - loss: 2.0480 - acc: 0.3000 - val_loss: 2.1928 - val_acc: 0.1000\n",
      "Epoch 56/1000\n",
      "80/80 [==============================] - 0s 495us/sample - loss: 2.0428 - acc: 0.3125 - val_loss: 2.1826 - val_acc: 0.1000\n",
      "Epoch 57/1000\n",
      "80/80 [==============================] - 0s 463us/sample - loss: 2.0402 - acc: 0.3250 - val_loss: 2.1878 - val_acc: 0.1000\n",
      "Epoch 58/1000\n",
      "80/80 [==============================] - 0s 441us/sample - loss: 2.0363 - acc: 0.3000 - val_loss: 2.1824 - val_acc: 0.1500\n",
      "Epoch 59/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 2.0347 - acc: 0.3125 - val_loss: 2.1844 - val_acc: 0.1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000\n",
      "80/80 [==============================] - 0s 388us/sample - loss: 2.0312 - acc: 0.3125 - val_loss: 2.1831 - val_acc: 0.1500\n",
      "Epoch 61/1000\n",
      "80/80 [==============================] - 0s 367us/sample - loss: 2.0292 - acc: 0.3000 - val_loss: 2.1858 - val_acc: 0.1500\n",
      "Epoch 62/1000\n",
      "80/80 [==============================] - 0s 483us/sample - loss: 2.0226 - acc: 0.2875 - val_loss: 2.1792 - val_acc: 0.1500\n",
      "Epoch 63/1000\n",
      "80/80 [==============================] - 0s 442us/sample - loss: 2.0194 - acc: 0.2875 - val_loss: 2.1881 - val_acc: 0.1500\n",
      "Epoch 64/1000\n",
      "80/80 [==============================] - 0s 473us/sample - loss: 2.0190 - acc: 0.2875 - val_loss: 2.1819 - val_acc: 0.1500\n",
      "Epoch 65/1000\n",
      "80/80 [==============================] - 0s 440us/sample - loss: 2.0138 - acc: 0.3000 - val_loss: 2.1855 - val_acc: 0.1500\n",
      "Epoch 66/1000\n",
      "80/80 [==============================] - 0s 450us/sample - loss: 2.0111 - acc: 0.2750 - val_loss: 2.1809 - val_acc: 0.1000\n",
      "Epoch 67/1000\n",
      "80/80 [==============================] - 0s 456us/sample - loss: 2.0048 - acc: 0.2875 - val_loss: 2.1724 - val_acc: 0.1000\n",
      "Epoch 68/1000\n",
      "80/80 [==============================] - 0s 402us/sample - loss: 2.0044 - acc: 0.2875 - val_loss: 2.1711 - val_acc: 0.1000\n",
      "Epoch 69/1000\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 2.0017 - acc: 0.3000 - val_loss: 2.1755 - val_acc: 0.1000\n",
      "Epoch 70/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 1.9969 - acc: 0.2750 - val_loss: 2.1700 - val_acc: 0.1000\n",
      "Epoch 71/1000\n",
      "80/80 [==============================] - 0s 447us/sample - loss: 1.9959 - acc: 0.3000 - val_loss: 2.1702 - val_acc: 0.1000\n",
      "Epoch 72/1000\n",
      "80/80 [==============================] - 0s 439us/sample - loss: 1.9918 - acc: 0.2875 - val_loss: 2.1695 - val_acc: 0.1000\n",
      "Epoch 73/1000\n",
      "80/80 [==============================] - 0s 442us/sample - loss: 1.9907 - acc: 0.2875 - val_loss: 2.1673 - val_acc: 0.1000\n",
      "Epoch 74/1000\n",
      "80/80 [==============================] - 0s 489us/sample - loss: 1.9877 - acc: 0.2875 - val_loss: 2.1693 - val_acc: 0.1000\n",
      "Epoch 75/1000\n",
      "80/80 [==============================] - 0s 429us/sample - loss: 1.9846 - acc: 0.3000 - val_loss: 2.1676 - val_acc: 0.1000\n",
      "Epoch 76/1000\n",
      "80/80 [==============================] - 0s 444us/sample - loss: 1.9797 - acc: 0.3000 - val_loss: 2.1737 - val_acc: 0.1000\n",
      "Epoch 77/1000\n",
      "80/80 [==============================] - 0s 398us/sample - loss: 1.9787 - acc: 0.3000 - val_loss: 2.1607 - val_acc: 0.1000\n",
      "Epoch 78/1000\n",
      "80/80 [==============================] - 0s 388us/sample - loss: 1.9759 - acc: 0.3000 - val_loss: 2.1667 - val_acc: 0.1000\n",
      "Epoch 79/1000\n",
      "80/80 [==============================] - 0s 398us/sample - loss: 1.9707 - acc: 0.3000 - val_loss: 2.1680 - val_acc: 0.1000\n",
      "Epoch 80/1000\n",
      "80/80 [==============================] - 0s 389us/sample - loss: 1.9687 - acc: 0.3000 - val_loss: 2.1743 - val_acc: 0.1000\n",
      "Epoch 81/1000\n",
      "80/80 [==============================] - 0s 420us/sample - loss: 1.9689 - acc: 0.3000 - val_loss: 2.1618 - val_acc: 0.1000\n",
      "Epoch 82/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 1.9635 - acc: 0.3000 - val_loss: 2.1646 - val_acc: 0.1000\n",
      "Epoch 83/1000\n",
      "80/80 [==============================] - 0s 482us/sample - loss: 1.9642 - acc: 0.3000 - val_loss: 2.1603 - val_acc: 0.1000\n",
      "Epoch 84/1000\n",
      "80/80 [==============================] - 0s 392us/sample - loss: 1.9593 - acc: 0.3000 - val_loss: 2.1599 - val_acc: 0.1000\n",
      "Epoch 85/1000\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 1.9566 - acc: 0.3000 - val_loss: 2.1596 - val_acc: 0.1000\n",
      "Epoch 86/1000\n",
      "80/80 [==============================] - 0s 356us/sample - loss: 1.9534 - acc: 0.3000 - val_loss: 2.1542 - val_acc: 0.1000\n",
      "Epoch 87/1000\n",
      "80/80 [==============================] - 0s 478us/sample - loss: 1.9523 - acc: 0.3000 - val_loss: 2.1523 - val_acc: 0.1000\n",
      "Epoch 88/1000\n",
      "80/80 [==============================] - 0s 487us/sample - loss: 1.9512 - acc: 0.3000 - val_loss: 2.1551 - val_acc: 0.1000\n",
      "Epoch 89/1000\n",
      "80/80 [==============================] - 0s 477us/sample - loss: 1.9480 - acc: 0.3000 - val_loss: 2.1613 - val_acc: 0.1000\n",
      "Epoch 90/1000\n",
      "80/80 [==============================] - 0s 457us/sample - loss: 1.9453 - acc: 0.3000 - val_loss: 2.1579 - val_acc: 0.1000\n",
      "Epoch 91/1000\n",
      "80/80 [==============================] - 0s 478us/sample - loss: 1.9432 - acc: 0.3000 - val_loss: 2.1557 - val_acc: 0.1000\n",
      "Epoch 92/1000\n",
      "80/80 [==============================] - 0s 432us/sample - loss: 1.9392 - acc: 0.3000 - val_loss: 2.1553 - val_acc: 0.1000\n",
      "Epoch 93/1000\n",
      "80/80 [==============================] - 0s 444us/sample - loss: 1.9370 - acc: 0.3000 - val_loss: 2.1613 - val_acc: 0.1000\n",
      "Epoch 94/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 1.9355 - acc: 0.3000 - val_loss: 2.1500 - val_acc: 0.1000\n",
      "Epoch 95/1000\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 1.9334 - acc: 0.3000 - val_loss: 2.1584 - val_acc: 0.1000\n",
      "Epoch 96/1000\n",
      "80/80 [==============================] - 0s 462us/sample - loss: 1.9334 - acc: 0.3000 - val_loss: 2.1583 - val_acc: 0.1000\n",
      "Epoch 97/1000\n",
      "80/80 [==============================] - 0s 390us/sample - loss: 1.9287 - acc: 0.3000 - val_loss: 2.1525 - val_acc: 0.1000\n",
      "Epoch 98/1000\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 1.9274 - acc: 0.3000 - val_loss: 2.1544 - val_acc: 0.1000\n",
      "Epoch 99/1000\n",
      "80/80 [==============================] - 0s 438us/sample - loss: 1.9254 - acc: 0.3000 - val_loss: 2.1516 - val_acc: 0.1000\n",
      "Epoch 100/1000\n",
      "80/80 [==============================] - 0s 455us/sample - loss: 1.9238 - acc: 0.3000 - val_loss: 2.1541 - val_acc: 0.1000\n",
      "Epoch 101/1000\n",
      "80/80 [==============================] - 0s 459us/sample - loss: 1.9209 - acc: 0.3000 - val_loss: 2.1526 - val_acc: 0.1000\n",
      "Epoch 102/1000\n",
      "80/80 [==============================] - 0s 459us/sample - loss: 1.9197 - acc: 0.3000 - val_loss: 2.1537 - val_acc: 0.1000\n",
      "Epoch 103/1000\n",
      "80/80 [==============================] - 0s 419us/sample - loss: 1.9152 - acc: 0.3000 - val_loss: 2.1506 - val_acc: 0.1000\n",
      "Epoch 104/1000\n",
      "80/80 [==============================] - 0s 427us/sample - loss: 1.9140 - acc: 0.3000 - val_loss: 2.1486 - val_acc: 0.1000\n",
      "Epoch 105/1000\n",
      "80/80 [==============================] - 0s 446us/sample - loss: 1.9117 - acc: 0.3000 - val_loss: 2.1522 - val_acc: 0.1000\n",
      "Epoch 106/1000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 1.9103 - acc: 0.3000 - val_loss: 2.1455 - val_acc: 0.1000\n",
      "Epoch 107/1000\n",
      "80/80 [==============================] - 0s 432us/sample - loss: 1.9076 - acc: 0.3000 - val_loss: 2.1412 - val_acc: 0.1000\n",
      "Epoch 108/1000\n",
      "80/80 [==============================] - 0s 404us/sample - loss: 1.9072 - acc: 0.3000 - val_loss: 2.1484 - val_acc: 0.1000\n",
      "Epoch 109/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 1.9060 - acc: 0.3000 - val_loss: 2.1422 - val_acc: 0.1000\n",
      "Epoch 110/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 1.9011 - acc: 0.3000 - val_loss: 2.1456 - val_acc: 0.1000\n",
      "Epoch 111/1000\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 1.8999 - acc: 0.3000 - val_loss: 2.1426 - val_acc: 0.1000\n",
      "Epoch 112/1000\n",
      "80/80 [==============================] - 0s 455us/sample - loss: 1.8969 - acc: 0.3000 - val_loss: 2.1383 - val_acc: 0.1000\n",
      "Epoch 113/1000\n",
      "80/80 [==============================] - 0s 398us/sample - loss: 1.8945 - acc: 0.3000 - val_loss: 2.1436 - val_acc: 0.1000\n",
      "Epoch 114/1000\n",
      "80/80 [==============================] - 0s 417us/sample - loss: 1.8920 - acc: 0.3000 - val_loss: 2.1392 - val_acc: 0.1000\n",
      "Epoch 115/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 1.8917 - acc: 0.3000 - val_loss: 2.1417 - val_acc: 0.1000\n",
      "Epoch 116/1000\n",
      "80/80 [==============================] - 0s 402us/sample - loss: 1.8903 - acc: 0.3000 - val_loss: 2.1390 - val_acc: 0.1000\n",
      "Epoch 117/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 1.8877 - acc: 0.3000 - val_loss: 2.1329 - val_acc: 0.1000\n",
      "Epoch 118/1000\n",
      "80/80 [==============================] - 0s 415us/sample - loss: 1.8877 - acc: 0.3000 - val_loss: 2.1367 - val_acc: 0.1000\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 443us/sample - loss: 1.8828 - acc: 0.3000 - val_loss: 2.1422 - val_acc: 0.1000\n",
      "Epoch 120/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 1.8798 - acc: 0.3000 - val_loss: 2.1275 - val_acc: 0.1000\n",
      "Epoch 121/1000\n",
      "80/80 [==============================] - 0s 491us/sample - loss: 1.8770 - acc: 0.3000 - val_loss: 2.1278 - val_acc: 0.1000\n",
      "Epoch 122/1000\n",
      "80/80 [==============================] - 0s 418us/sample - loss: 1.8718 - acc: 0.3000 - val_loss: 2.1154 - val_acc: 0.1500\n",
      "Epoch 123/1000\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 1.8679 - acc: 0.3000 - val_loss: 2.1012 - val_acc: 0.1500\n",
      "Epoch 124/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 1.8622 - acc: 0.2750 - val_loss: 2.0821 - val_acc: 0.1500\n",
      "Epoch 125/1000\n",
      "80/80 [==============================] - 0s 493us/sample - loss: 1.8583 - acc: 0.2750 - val_loss: 2.0777 - val_acc: 0.1500\n",
      "Epoch 126/1000\n",
      "80/80 [==============================] - 0s 466us/sample - loss: 1.8519 - acc: 0.2875 - val_loss: 2.0456 - val_acc: 0.1500\n",
      "Epoch 127/1000\n",
      "80/80 [==============================] - 0s 542us/sample - loss: 1.8450 - acc: 0.2750 - val_loss: 2.0164 - val_acc: 0.1000\n",
      "Epoch 128/1000\n",
      "80/80 [==============================] - 0s 396us/sample - loss: 1.8406 - acc: 0.2750 - val_loss: 2.0164 - val_acc: 0.1500\n",
      "Epoch 129/1000\n",
      "80/80 [==============================] - 0s 408us/sample - loss: 1.8352 - acc: 0.2750 - val_loss: 2.0111 - val_acc: 0.1500\n",
      "Epoch 130/1000\n",
      "80/80 [==============================] - 0s 427us/sample - loss: 1.8303 - acc: 0.2750 - val_loss: 1.9821 - val_acc: 0.1000\n",
      "Epoch 131/1000\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 1.8300 - acc: 0.2750 - val_loss: 1.9986 - val_acc: 0.1500\n",
      "Epoch 132/1000\n",
      "80/80 [==============================] - 0s 427us/sample - loss: 1.8170 - acc: 0.2750 - val_loss: 1.9897 - val_acc: 0.1500\n",
      "Epoch 133/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 1.8169 - acc: 0.2875 - val_loss: 1.9928 - val_acc: 0.1500\n",
      "Epoch 134/1000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 1.8136 - acc: 0.2875 - val_loss: 1.9528 - val_acc: 0.1500\n",
      "Epoch 135/1000\n",
      "80/80 [==============================] - 0s 400us/sample - loss: 1.7999 - acc: 0.3000 - val_loss: 1.9811 - val_acc: 0.1500\n",
      "Epoch 136/1000\n",
      "80/80 [==============================] - 0s 443us/sample - loss: 1.7994 - acc: 0.3125 - val_loss: 1.9508 - val_acc: 0.1500\n",
      "Epoch 137/1000\n",
      "80/80 [==============================] - 0s 429us/sample - loss: 1.7944 - acc: 0.2875 - val_loss: 1.9708 - val_acc: 0.1500\n",
      "Epoch 138/1000\n",
      "80/80 [==============================] - 0s 428us/sample - loss: 1.7927 - acc: 0.3000 - val_loss: 1.9469 - val_acc: 0.1500\n",
      "Epoch 139/1000\n",
      "80/80 [==============================] - 0s 420us/sample - loss: 1.7823 - acc: 0.3125 - val_loss: 1.9521 - val_acc: 0.1500\n",
      "Epoch 140/1000\n",
      "80/80 [==============================] - 0s 378us/sample - loss: 1.7808 - acc: 0.3375 - val_loss: 1.9450 - val_acc: 0.1500\n",
      "Epoch 141/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 1.7718 - acc: 0.3250 - val_loss: 1.9183 - val_acc: 0.1500\n",
      "Epoch 142/1000\n",
      "80/80 [==============================] - 0s 392us/sample - loss: 1.7704 - acc: 0.3000 - val_loss: 1.9280 - val_acc: 0.1500\n",
      "Epoch 143/1000\n",
      "80/80 [==============================] - 0s 378us/sample - loss: 1.7629 - acc: 0.3375 - val_loss: 1.9043 - val_acc: 0.1500\n",
      "Epoch 144/1000\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 1.7652 - acc: 0.3375 - val_loss: 1.8967 - val_acc: 0.1500\n",
      "Epoch 145/1000\n",
      "80/80 [==============================] - 0s 342us/sample - loss: 1.7518 - acc: 0.3375 - val_loss: 1.9197 - val_acc: 0.1500\n",
      "Epoch 146/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 1.7492 - acc: 0.3375 - val_loss: 1.8935 - val_acc: 0.1000\n",
      "Epoch 147/1000\n",
      "80/80 [==============================] - 0s 487us/sample - loss: 1.7439 - acc: 0.3625 - val_loss: 1.8998 - val_acc: 0.1500\n",
      "Epoch 148/1000\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 1.7448 - acc: 0.3375 - val_loss: 1.8822 - val_acc: 0.1500\n",
      "Epoch 149/1000\n",
      "80/80 [==============================] - 0s 463us/sample - loss: 1.7376 - acc: 0.3625 - val_loss: 1.8861 - val_acc: 0.1500\n",
      "Epoch 150/1000\n",
      "80/80 [==============================] - 0s 352us/sample - loss: 1.7309 - acc: 0.3625 - val_loss: 1.8660 - val_acc: 0.1000\n",
      "Epoch 151/1000\n",
      "80/80 [==============================] - 0s 438us/sample - loss: 1.7298 - acc: 0.3625 - val_loss: 1.8592 - val_acc: 0.1000\n",
      "Epoch 152/1000\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 1.7201 - acc: 0.3750 - val_loss: 1.8417 - val_acc: 0.1000\n",
      "Epoch 153/1000\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 1.7158 - acc: 0.3625 - val_loss: 1.8601 - val_acc: 0.1000\n",
      "Epoch 154/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 1.7131 - acc: 0.3875 - val_loss: 1.8398 - val_acc: 0.1000\n",
      "Epoch 155/1000\n",
      "80/80 [==============================] - 0s 348us/sample - loss: 1.7060 - acc: 0.3750 - val_loss: 1.8321 - val_acc: 0.1000\n",
      "Epoch 156/1000\n",
      "80/80 [==============================] - 0s 412us/sample - loss: 1.7007 - acc: 0.3750 - val_loss: 1.8176 - val_acc: 0.1500\n",
      "Epoch 157/1000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 1.6974 - acc: 0.3625 - val_loss: 1.8321 - val_acc: 0.1500\n",
      "Epoch 158/1000\n",
      "80/80 [==============================] - 0s 417us/sample - loss: 1.6987 - acc: 0.3750 - val_loss: 1.8289 - val_acc: 0.2000\n",
      "Epoch 159/1000\n",
      "80/80 [==============================] - 0s 445us/sample - loss: 1.6890 - acc: 0.3750 - val_loss: 1.8181 - val_acc: 0.2000\n",
      "Epoch 160/1000\n",
      "80/80 [==============================] - 0s 420us/sample - loss: 1.6796 - acc: 0.3750 - val_loss: 1.7953 - val_acc: 0.2000\n",
      "Epoch 161/1000\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 1.6766 - acc: 0.3625 - val_loss: 1.8026 - val_acc: 0.2500\n",
      "Epoch 162/1000\n",
      "80/80 [==============================] - 0s 437us/sample - loss: 1.6742 - acc: 0.3625 - val_loss: 1.7848 - val_acc: 0.2500\n",
      "Epoch 163/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 1.6690 - acc: 0.3625 - val_loss: 1.7791 - val_acc: 0.2500\n",
      "Epoch 164/1000\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 1.6663 - acc: 0.3625 - val_loss: 1.7950 - val_acc: 0.4000\n",
      "Epoch 165/1000\n",
      "80/80 [==============================] - 0s 398us/sample - loss: 1.6571 - acc: 0.4125 - val_loss: 1.7493 - val_acc: 0.3500\n",
      "Epoch 166/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 1.6523 - acc: 0.3875 - val_loss: 1.7511 - val_acc: 0.3500\n",
      "Epoch 167/1000\n",
      "80/80 [==============================] - 0s 376us/sample - loss: 1.6495 - acc: 0.3875 - val_loss: 1.7518 - val_acc: 0.4000\n",
      "Epoch 168/1000\n",
      "80/80 [==============================] - 0s 390us/sample - loss: 1.6404 - acc: 0.4250 - val_loss: 1.7215 - val_acc: 0.3500\n",
      "Epoch 169/1000\n",
      "80/80 [==============================] - 0s 354us/sample - loss: 1.6396 - acc: 0.4125 - val_loss: 1.7469 - val_acc: 0.4000\n",
      "Epoch 170/1000\n",
      "80/80 [==============================] - 0s 426us/sample - loss: 1.6334 - acc: 0.4250 - val_loss: 1.7202 - val_acc: 0.4000\n",
      "Epoch 171/1000\n",
      "80/80 [==============================] - 0s 402us/sample - loss: 1.6295 - acc: 0.4250 - val_loss: 1.7185 - val_acc: 0.4000\n",
      "Epoch 172/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 1.6234 - acc: 0.4125 - val_loss: 1.7197 - val_acc: 0.4000\n",
      "Epoch 173/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 1.6217 - acc: 0.4250 - val_loss: 1.7126 - val_acc: 0.4000\n",
      "Epoch 174/1000\n",
      "80/80 [==============================] - 0s 401us/sample - loss: 1.6142 - acc: 0.4125 - val_loss: 1.6941 - val_acc: 0.4000\n",
      "Epoch 175/1000\n",
      "80/80 [==============================] - 0s 453us/sample - loss: 1.6082 - acc: 0.4125 - val_loss: 1.6951 - val_acc: 0.4000\n",
      "Epoch 176/1000\n",
      "80/80 [==============================] - 0s 402us/sample - loss: 1.6043 - acc: 0.4125 - val_loss: 1.6853 - val_acc: 0.4000\n",
      "Epoch 177/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 1.6005 - acc: 0.4375 - val_loss: 1.6883 - val_acc: 0.4000\n",
      "Epoch 178/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 421us/sample - loss: 1.5953 - acc: 0.4625 - val_loss: 1.6732 - val_acc: 0.4000\n",
      "Epoch 179/1000\n",
      "80/80 [==============================] - 0s 434us/sample - loss: 1.5926 - acc: 0.4500 - val_loss: 1.6667 - val_acc: 0.4000\n",
      "Epoch 180/1000\n",
      "80/80 [==============================] - 0s 438us/sample - loss: 1.5902 - acc: 0.4500 - val_loss: 1.6652 - val_acc: 0.4000\n",
      "Epoch 181/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 1.5859 - acc: 0.4625 - val_loss: 1.6547 - val_acc: 0.4000\n",
      "Epoch 182/1000\n",
      "80/80 [==============================] - 0s 465us/sample - loss: 1.5797 - acc: 0.4625 - val_loss: 1.6534 - val_acc: 0.4000\n",
      "Epoch 183/1000\n",
      "80/80 [==============================] - 0s 504us/sample - loss: 1.5736 - acc: 0.4625 - val_loss: 1.6412 - val_acc: 0.4000\n",
      "Epoch 184/1000\n",
      "80/80 [==============================] - 0s 470us/sample - loss: 1.5702 - acc: 0.4625 - val_loss: 1.6384 - val_acc: 0.4000\n",
      "Epoch 185/1000\n",
      "80/80 [==============================] - 0s 516us/sample - loss: 1.5632 - acc: 0.4625 - val_loss: 1.6309 - val_acc: 0.4000\n",
      "Epoch 186/1000\n",
      "80/80 [==============================] - 0s 562us/sample - loss: 1.5608 - acc: 0.4875 - val_loss: 1.6328 - val_acc: 0.4500\n",
      "Epoch 187/1000\n",
      "80/80 [==============================] - 0s 491us/sample - loss: 1.5578 - acc: 0.4625 - val_loss: 1.6224 - val_acc: 0.4000\n",
      "Epoch 188/1000\n",
      "80/80 [==============================] - 0s 535us/sample - loss: 1.5506 - acc: 0.4750 - val_loss: 1.6143 - val_acc: 0.4000\n",
      "Epoch 189/1000\n",
      "80/80 [==============================] - 0s 526us/sample - loss: 1.5472 - acc: 0.4875 - val_loss: 1.6010 - val_acc: 0.4000\n",
      "Epoch 190/1000\n",
      "80/80 [==============================] - 0s 537us/sample - loss: 1.5413 - acc: 0.4750 - val_loss: 1.5951 - val_acc: 0.4000\n",
      "Epoch 191/1000\n",
      "80/80 [==============================] - 0s 522us/sample - loss: 1.5392 - acc: 0.4750 - val_loss: 1.5950 - val_acc: 0.4000\n",
      "Epoch 192/1000\n",
      "80/80 [==============================] - 0s 558us/sample - loss: 1.5351 - acc: 0.4875 - val_loss: 1.5983 - val_acc: 0.4500\n",
      "Epoch 193/1000\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 1.5326 - acc: 0.4875 - val_loss: 1.5860 - val_acc: 0.4000\n",
      "Epoch 194/1000\n",
      "80/80 [==============================] - 0s 527us/sample - loss: 1.5288 - acc: 0.4875 - val_loss: 1.5901 - val_acc: 0.4500\n",
      "Epoch 195/1000\n",
      "80/80 [==============================] - 0s 502us/sample - loss: 1.5206 - acc: 0.4875 - val_loss: 1.5953 - val_acc: 0.4500\n",
      "Epoch 196/1000\n",
      "80/80 [==============================] - 0s 494us/sample - loss: 1.5173 - acc: 0.4750 - val_loss: 1.5868 - val_acc: 0.4500\n",
      "Epoch 197/1000\n",
      "80/80 [==============================] - 0s 522us/sample - loss: 1.5132 - acc: 0.4875 - val_loss: 1.5913 - val_acc: 0.4500\n",
      "Epoch 198/1000\n",
      "80/80 [==============================] - 0s 471us/sample - loss: 1.5106 - acc: 0.4875 - val_loss: 1.5791 - val_acc: 0.4500\n",
      "Epoch 199/1000\n",
      "80/80 [==============================] - 0s 542us/sample - loss: 1.5095 - acc: 0.4750 - val_loss: 1.5713 - val_acc: 0.4500\n",
      "Epoch 200/1000\n",
      "80/80 [==============================] - 0s 512us/sample - loss: 1.5018 - acc: 0.4875 - val_loss: 1.5566 - val_acc: 0.4500\n",
      "Epoch 201/1000\n",
      "80/80 [==============================] - 0s 453us/sample - loss: 1.5020 - acc: 0.4750 - val_loss: 1.5586 - val_acc: 0.4500\n",
      "Epoch 202/1000\n",
      "80/80 [==============================] - 0s 482us/sample - loss: 1.4942 - acc: 0.4750 - val_loss: 1.5599 - val_acc: 0.4500\n",
      "Epoch 203/1000\n",
      "80/80 [==============================] - 0s 396us/sample - loss: 1.4911 - acc: 0.4750 - val_loss: 1.5444 - val_acc: 0.4500\n",
      "Epoch 204/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 1.4896 - acc: 0.4750 - val_loss: 1.5512 - val_acc: 0.4500\n",
      "Epoch 205/1000\n",
      "80/80 [==============================] - 0s 426us/sample - loss: 1.4827 - acc: 0.5000 - val_loss: 1.5323 - val_acc: 0.4500\n",
      "Epoch 206/1000\n",
      "80/80 [==============================] - 0s 389us/sample - loss: 1.4802 - acc: 0.4875 - val_loss: 1.5401 - val_acc: 0.4500\n",
      "Epoch 207/1000\n",
      "80/80 [==============================] - 0s 389us/sample - loss: 1.4757 - acc: 0.5000 - val_loss: 1.5337 - val_acc: 0.4500\n",
      "Epoch 208/1000\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 1.4741 - acc: 0.5000 - val_loss: 1.5389 - val_acc: 0.4500\n",
      "Epoch 209/1000\n",
      "80/80 [==============================] - 0s 410us/sample - loss: 1.4671 - acc: 0.5000 - val_loss: 1.5267 - val_acc: 0.4500\n",
      "Epoch 210/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 1.4645 - acc: 0.5000 - val_loss: 1.5431 - val_acc: 0.4500\n",
      "Epoch 211/1000\n",
      "80/80 [==============================] - 0s 389us/sample - loss: 1.4614 - acc: 0.5000 - val_loss: 1.5342 - val_acc: 0.4500\n",
      "Epoch 212/1000\n",
      "80/80 [==============================] - 0s 403us/sample - loss: 1.4578 - acc: 0.5000 - val_loss: 1.5169 - val_acc: 0.4500\n",
      "Epoch 213/1000\n",
      "80/80 [==============================] - 0s 401us/sample - loss: 1.4574 - acc: 0.5000 - val_loss: 1.5179 - val_acc: 0.4500\n",
      "Epoch 214/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 1.4511 - acc: 0.5000 - val_loss: 1.5304 - val_acc: 0.5000\n",
      "Epoch 215/1000\n",
      "80/80 [==============================] - 0s 416us/sample - loss: 1.4503 - acc: 0.5000 - val_loss: 1.5146 - val_acc: 0.5000\n",
      "Epoch 216/1000\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 1.4466 - acc: 0.4875 - val_loss: 1.5266 - val_acc: 0.5000\n",
      "Epoch 217/1000\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 1.4407 - acc: 0.5000 - val_loss: 1.5083 - val_acc: 0.5000\n",
      "Epoch 218/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 1.4388 - acc: 0.5000 - val_loss: 1.5125 - val_acc: 0.5000\n",
      "Epoch 219/1000\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 1.4335 - acc: 0.5000 - val_loss: 1.5062 - val_acc: 0.5000\n",
      "Epoch 220/1000\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 1.4327 - acc: 0.5125 - val_loss: 1.5194 - val_acc: 0.5000\n",
      "Epoch 221/1000\n",
      "80/80 [==============================] - 0s 460us/sample - loss: 1.4295 - acc: 0.5000 - val_loss: 1.5094 - val_acc: 0.5000\n",
      "Epoch 222/1000\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 1.4232 - acc: 0.5000 - val_loss: 1.5099 - val_acc: 0.5000\n",
      "Epoch 223/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 1.4221 - acc: 0.5000 - val_loss: 1.4924 - val_acc: 0.5000\n",
      "Epoch 224/1000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 1.4193 - acc: 0.5000 - val_loss: 1.4994 - val_acc: 0.5000\n",
      "Epoch 225/1000\n",
      "80/80 [==============================] - 0s 432us/sample - loss: 1.4170 - acc: 0.5000 - val_loss: 1.4925 - val_acc: 0.5000\n",
      "Epoch 226/1000\n",
      "80/80 [==============================] - 0s 385us/sample - loss: 1.4114 - acc: 0.5000 - val_loss: 1.4972 - val_acc: 0.5000\n",
      "Epoch 227/1000\n",
      "80/80 [==============================] - 0s 390us/sample - loss: 1.4091 - acc: 0.5000 - val_loss: 1.4936 - val_acc: 0.5000\n",
      "Epoch 228/1000\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 1.4045 - acc: 0.5000 - val_loss: 1.4848 - val_acc: 0.5000\n",
      "Epoch 229/1000\n",
      "80/80 [==============================] - 0s 473us/sample - loss: 1.4061 - acc: 0.5125 - val_loss: 1.4933 - val_acc: 0.5000\n",
      "Epoch 230/1000\n",
      "80/80 [==============================] - 0s 431us/sample - loss: 1.4020 - acc: 0.5000 - val_loss: 1.4886 - val_acc: 0.5000\n",
      "Epoch 231/1000\n",
      "80/80 [==============================] - 0s 465us/sample - loss: 1.3989 - acc: 0.5000 - val_loss: 1.4873 - val_acc: 0.5000\n",
      "Epoch 232/1000\n",
      "80/80 [==============================] - 0s 392us/sample - loss: 1.3941 - acc: 0.5000 - val_loss: 1.4881 - val_acc: 0.5000\n",
      "Epoch 233/1000\n",
      "80/80 [==============================] - 0s 415us/sample - loss: 1.3904 - acc: 0.5000 - val_loss: 1.4742 - val_acc: 0.5000\n",
      "Epoch 234/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 1.3922 - acc: 0.5125 - val_loss: 1.4810 - val_acc: 0.5000\n",
      "Epoch 235/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 1.3895 - acc: 0.5000 - val_loss: 1.4823 - val_acc: 0.5000\n",
      "Epoch 236/1000\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 1.3821 - acc: 0.4875 - val_loss: 1.4846 - val_acc: 0.5000\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 380us/sample - loss: 1.3818 - acc: 0.5125 - val_loss: 1.4794 - val_acc: 0.5000\n",
      "Epoch 238/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 1.3766 - acc: 0.5000 - val_loss: 1.4825 - val_acc: 0.5000\n",
      "Epoch 239/1000\n",
      "80/80 [==============================] - 0s 352us/sample - loss: 1.3745 - acc: 0.5000 - val_loss: 1.4765 - val_acc: 0.5000\n",
      "Epoch 240/1000\n",
      "80/80 [==============================] - 0s 511us/sample - loss: 1.3722 - acc: 0.5000 - val_loss: 1.4771 - val_acc: 0.5000\n",
      "Epoch 241/1000\n",
      "80/80 [==============================] - 0s 471us/sample - loss: 1.3667 - acc: 0.5000 - val_loss: 1.4673 - val_acc: 0.5000\n",
      "Epoch 242/1000\n",
      "80/80 [==============================] - 0s 484us/sample - loss: 1.3659 - acc: 0.5125 - val_loss: 1.4788 - val_acc: 0.5000\n",
      "Epoch 243/1000\n",
      "80/80 [==============================] - 0s 476us/sample - loss: 1.3624 - acc: 0.5250 - val_loss: 1.4790 - val_acc: 0.5000\n",
      "Epoch 244/1000\n",
      "80/80 [==============================] - 0s 502us/sample - loss: 1.3618 - acc: 0.5125 - val_loss: 1.4715 - val_acc: 0.5000\n",
      "Epoch 245/1000\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 1.3591 - acc: 0.5000 - val_loss: 1.4691 - val_acc: 0.5000\n",
      "Epoch 246/1000\n",
      "80/80 [==============================] - 0s 429us/sample - loss: 1.3551 - acc: 0.5000 - val_loss: 1.4732 - val_acc: 0.5000\n",
      "Epoch 247/1000\n",
      "80/80 [==============================] - 0s 500us/sample - loss: 1.3529 - acc: 0.5000 - val_loss: 1.4709 - val_acc: 0.5000\n",
      "Epoch 248/1000\n",
      "80/80 [==============================] - 0s 466us/sample - loss: 1.3497 - acc: 0.5125 - val_loss: 1.4737 - val_acc: 0.5000\n",
      "Epoch 249/1000\n",
      "80/80 [==============================] - 0s 432us/sample - loss: 1.3500 - acc: 0.5125 - val_loss: 1.4694 - val_acc: 0.5000\n",
      "Epoch 250/1000\n",
      "80/80 [==============================] - 0s 462us/sample - loss: 1.3461 - acc: 0.5125 - val_loss: 1.4617 - val_acc: 0.5000\n",
      "Epoch 251/1000\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 1.3422 - acc: 0.5125 - val_loss: 1.4741 - val_acc: 0.5000\n",
      "Epoch 252/1000\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 1.3389 - acc: 0.5125 - val_loss: 1.4628 - val_acc: 0.5000\n",
      "Epoch 253/1000\n",
      "80/80 [==============================] - 0s 463us/sample - loss: 1.3376 - acc: 0.5125 - val_loss: 1.4643 - val_acc: 0.5000\n",
      "Epoch 254/1000\n",
      "80/80 [==============================] - 0s 481us/sample - loss: 1.3343 - acc: 0.5125 - val_loss: 1.4724 - val_acc: 0.5000\n",
      "Epoch 255/1000\n",
      "80/80 [==============================] - 0s 527us/sample - loss: 1.3325 - acc: 0.5125 - val_loss: 1.4616 - val_acc: 0.5000\n",
      "Epoch 256/1000\n",
      "80/80 [==============================] - 0s 489us/sample - loss: 1.3310 - acc: 0.5125 - val_loss: 1.4739 - val_acc: 0.5000\n",
      "Epoch 257/1000\n",
      "80/80 [==============================] - 0s 429us/sample - loss: 1.3263 - acc: 0.5000 - val_loss: 1.4644 - val_acc: 0.5000\n",
      "Epoch 258/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 1.3260 - acc: 0.5000 - val_loss: 1.4589 - val_acc: 0.5000\n",
      "Epoch 259/1000\n",
      "80/80 [==============================] - 0s 389us/sample - loss: 1.3228 - acc: 0.5125 - val_loss: 1.4544 - val_acc: 0.5000\n",
      "Epoch 260/1000\n",
      "80/80 [==============================] - 0s 365us/sample - loss: 1.3217 - acc: 0.5125 - val_loss: 1.4624 - val_acc: 0.5000\n",
      "Epoch 261/1000\n",
      "80/80 [==============================] - 0s 455us/sample - loss: 1.3161 - acc: 0.5125 - val_loss: 1.4622 - val_acc: 0.5000\n",
      "Epoch 262/1000\n",
      "80/80 [==============================] - 0s 462us/sample - loss: 1.3138 - acc: 0.5125 - val_loss: 1.4688 - val_acc: 0.5000\n",
      "Epoch 263/1000\n",
      "80/80 [==============================] - 0s 482us/sample - loss: 1.3151 - acc: 0.5125 - val_loss: 1.4544 - val_acc: 0.5000\n",
      "Epoch 264/1000\n",
      "80/80 [==============================] - 0s 460us/sample - loss: 1.3128 - acc: 0.5125 - val_loss: 1.4519 - val_acc: 0.5000\n",
      "Epoch 265/1000\n",
      "80/80 [==============================] - 0s 447us/sample - loss: 1.3084 - acc: 0.5125 - val_loss: 1.4584 - val_acc: 0.5000\n",
      "Epoch 266/1000\n",
      "80/80 [==============================] - 0s 432us/sample - loss: 1.3063 - acc: 0.5125 - val_loss: 1.4469 - val_acc: 0.5000\n",
      "Epoch 267/1000\n",
      "80/80 [==============================] - 0s 483us/sample - loss: 1.3063 - acc: 0.5125 - val_loss: 1.4576 - val_acc: 0.5000\n",
      "Epoch 268/1000\n",
      "80/80 [==============================] - 0s 388us/sample - loss: 1.3013 - acc: 0.5125 - val_loss: 1.4566 - val_acc: 0.5000\n",
      "Epoch 269/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 1.3032 - acc: 0.5125 - val_loss: 1.4458 - val_acc: 0.5000\n",
      "Epoch 270/1000\n",
      "80/80 [==============================] - 0s 467us/sample - loss: 1.2978 - acc: 0.5125 - val_loss: 1.4442 - val_acc: 0.5000\n",
      "Epoch 271/1000\n",
      "80/80 [==============================] - 0s 493us/sample - loss: 1.2942 - acc: 0.5125 - val_loss: 1.4571 - val_acc: 0.5000\n",
      "Epoch 272/1000\n",
      "80/80 [==============================] - 0s 471us/sample - loss: 1.2934 - acc: 0.5125 - val_loss: 1.4543 - val_acc: 0.5000\n",
      "Epoch 273/1000\n",
      "80/80 [==============================] - 0s 447us/sample - loss: 1.2904 - acc: 0.5125 - val_loss: 1.4515 - val_acc: 0.5000\n",
      "Epoch 274/1000\n",
      "80/80 [==============================] - 0s 482us/sample - loss: 1.2879 - acc: 0.5125 - val_loss: 1.4504 - val_acc: 0.5000\n",
      "Epoch 275/1000\n",
      "80/80 [==============================] - 0s 728us/sample - loss: 1.2884 - acc: 0.5125 - val_loss: 1.4496 - val_acc: 0.5000\n",
      "Epoch 276/1000\n",
      "80/80 [==============================] - 0s 439us/sample - loss: 1.2848 - acc: 0.5125 - val_loss: 1.4458 - val_acc: 0.5000\n",
      "Epoch 277/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 1.2835 - acc: 0.5125 - val_loss: 1.4441 - val_acc: 0.5000\n",
      "Epoch 278/1000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 1.2795 - acc: 0.5125 - val_loss: 1.4469 - val_acc: 0.5000\n",
      "Epoch 279/1000\n",
      "80/80 [==============================] - 0s 408us/sample - loss: 1.2815 - acc: 0.5250 - val_loss: 1.4522 - val_acc: 0.5000\n",
      "Epoch 280/1000\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 1.2756 - acc: 0.5125 - val_loss: 1.4381 - val_acc: 0.5000\n",
      "Epoch 281/1000\n",
      "80/80 [==============================] - 0s 358us/sample - loss: 1.2749 - acc: 0.5125 - val_loss: 1.4428 - val_acc: 0.5000\n",
      "Epoch 282/1000\n",
      "80/80 [==============================] - 0s 326us/sample - loss: 1.2736 - acc: 0.5125 - val_loss: 1.4398 - val_acc: 0.5000\n",
      "Epoch 283/1000\n",
      "80/80 [==============================] - 0s 346us/sample - loss: 1.2706 - acc: 0.5125 - val_loss: 1.4374 - val_acc: 0.5000\n",
      "Epoch 284/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 1.2694 - acc: 0.5125 - val_loss: 1.4410 - val_acc: 0.5000\n",
      "Epoch 285/1000\n",
      "80/80 [==============================] - 0s 361us/sample - loss: 1.2653 - acc: 0.5125 - val_loss: 1.4541 - val_acc: 0.5000\n",
      "Epoch 286/1000\n",
      "80/80 [==============================] - 0s 316us/sample - loss: 1.2666 - acc: 0.5250 - val_loss: 1.4360 - val_acc: 0.5000\n",
      "Epoch 287/1000\n",
      "80/80 [==============================] - 0s 295us/sample - loss: 1.2618 - acc: 0.5125 - val_loss: 1.4394 - val_acc: 0.5000\n",
      "Epoch 288/1000\n",
      "80/80 [==============================] - 0s 334us/sample - loss: 1.2621 - acc: 0.5125 - val_loss: 1.4346 - val_acc: 0.5000\n",
      "Epoch 289/1000\n",
      "80/80 [==============================] - 0s 408us/sample - loss: 1.2561 - acc: 0.5125 - val_loss: 1.4486 - val_acc: 0.5000\n",
      "Epoch 290/1000\n",
      "80/80 [==============================] - 0s 369us/sample - loss: 1.2574 - acc: 0.5125 - val_loss: 1.4425 - val_acc: 0.5000\n",
      "Epoch 291/1000\n",
      "80/80 [==============================] - 0s 396us/sample - loss: 1.2540 - acc: 0.5125 - val_loss: 1.4426 - val_acc: 0.5000\n",
      "Epoch 292/1000\n",
      "80/80 [==============================] - 0s 376us/sample - loss: 1.2546 - acc: 0.5125 - val_loss: 1.4365 - val_acc: 0.5000\n",
      "Epoch 293/1000\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 1.2493 - acc: 0.5250 - val_loss: 1.4358 - val_acc: 0.5000\n",
      "Epoch 294/1000\n",
      "80/80 [==============================] - 0s 357us/sample - loss: 1.2471 - acc: 0.5125 - val_loss: 1.4446 - val_acc: 0.5000\n",
      "Epoch 295/1000\n",
      "80/80 [==============================] - 0s 419us/sample - loss: 1.2476 - acc: 0.5125 - val_loss: 1.4443 - val_acc: 0.5000\n",
      "Epoch 296/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 356us/sample - loss: 1.2452 - acc: 0.5375 - val_loss: 1.4357 - val_acc: 0.5000\n",
      "Epoch 297/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 1.2437 - acc: 0.5250 - val_loss: 1.4344 - val_acc: 0.5000\n",
      "Epoch 298/1000\n",
      "80/80 [==============================] - 0s 372us/sample - loss: 1.2403 - acc: 0.5125 - val_loss: 1.4313 - val_acc: 0.5000\n",
      "Epoch 299/1000\n",
      "80/80 [==============================] - 0s 340us/sample - loss: 1.2362 - acc: 0.5125 - val_loss: 1.4360 - val_acc: 0.5000\n",
      "Epoch 300/1000\n",
      "80/80 [==============================] - 0s 358us/sample - loss: 1.2387 - acc: 0.5250 - val_loss: 1.4250 - val_acc: 0.5000\n",
      "Epoch 301/1000\n",
      "80/80 [==============================] - 0s 361us/sample - loss: 1.2349 - acc: 0.5250 - val_loss: 1.4420 - val_acc: 0.5000\n",
      "Epoch 302/1000\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 1.2329 - acc: 0.5250 - val_loss: 1.4412 - val_acc: 0.5000\n",
      "Epoch 303/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 1.2327 - acc: 0.5375 - val_loss: 1.4349 - val_acc: 0.5000\n",
      "Epoch 304/1000\n",
      "80/80 [==============================] - 0s 313us/sample - loss: 1.2309 - acc: 0.5375 - val_loss: 1.4294 - val_acc: 0.5000\n",
      "Epoch 305/1000\n",
      "80/80 [==============================] - 0s 341us/sample - loss: 1.2284 - acc: 0.5250 - val_loss: 1.4387 - val_acc: 0.5000\n",
      "Epoch 306/1000\n",
      "80/80 [==============================] - 0s 317us/sample - loss: 1.2262 - acc: 0.5125 - val_loss: 1.4344 - val_acc: 0.5000\n",
      "Epoch 307/1000\n",
      "80/80 [==============================] - 0s 324us/sample - loss: 1.2240 - acc: 0.5250 - val_loss: 1.4379 - val_acc: 0.5000\n",
      "Epoch 308/1000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 1.2229 - acc: 0.5375 - val_loss: 1.4314 - val_acc: 0.5000\n",
      "Epoch 309/1000\n",
      "80/80 [==============================] - 0s 326us/sample - loss: 1.2201 - acc: 0.5375 - val_loss: 1.4350 - val_acc: 0.5000\n",
      "Epoch 310/1000\n",
      "80/80 [==============================] - 0s 324us/sample - loss: 1.2209 - acc: 0.5375 - val_loss: 1.4331 - val_acc: 0.5000\n",
      "Epoch 311/1000\n",
      "80/80 [==============================] - 0s 350us/sample - loss: 1.2154 - acc: 0.5625 - val_loss: 1.4386 - val_acc: 0.5000\n",
      "Epoch 312/1000\n",
      "80/80 [==============================] - 0s 384us/sample - loss: 1.2150 - acc: 0.5375 - val_loss: 1.4386 - val_acc: 0.5000\n",
      "Epoch 313/1000\n",
      "80/80 [==============================] - 0s 376us/sample - loss: 1.2132 - acc: 0.5500 - val_loss: 1.4276 - val_acc: 0.5000\n",
      "Epoch 314/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 1.2091 - acc: 0.5375 - val_loss: 1.4291 - val_acc: 0.5000\n",
      "Epoch 315/1000\n",
      "80/80 [==============================] - 0s 350us/sample - loss: 1.2101 - acc: 0.5375 - val_loss: 1.4273 - val_acc: 0.5000\n",
      "Epoch 316/1000\n",
      "80/80 [==============================] - 0s 388us/sample - loss: 1.2067 - acc: 0.5375 - val_loss: 1.4286 - val_acc: 0.5000\n",
      "Epoch 317/1000\n",
      "80/80 [==============================] - 0s 369us/sample - loss: 1.2066 - acc: 0.5375 - val_loss: 1.4315 - val_acc: 0.5000\n",
      "Epoch 318/1000\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 1.2053 - acc: 0.5625 - val_loss: 1.4258 - val_acc: 0.5000\n",
      "Epoch 319/1000\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 1.2009 - acc: 0.5375 - val_loss: 1.4213 - val_acc: 0.5000\n",
      "Epoch 320/1000\n",
      "80/80 [==============================] - 0s 443us/sample - loss: 1.2008 - acc: 0.5375 - val_loss: 1.4329 - val_acc: 0.5000\n",
      "Epoch 321/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 1.1978 - acc: 0.5375 - val_loss: 1.4255 - val_acc: 0.5000\n",
      "Epoch 322/1000\n",
      "80/80 [==============================] - 0s 324us/sample - loss: 1.1969 - acc: 0.5500 - val_loss: 1.4333 - val_acc: 0.5500\n",
      "Epoch 323/1000\n",
      "80/80 [==============================] - 0s 339us/sample - loss: 1.1953 - acc: 0.5375 - val_loss: 1.4445 - val_acc: 0.5500\n",
      "Epoch 324/1000\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 1.1938 - acc: 0.5375 - val_loss: 1.4271 - val_acc: 0.5000\n",
      "Epoch 325/1000\n",
      "80/80 [==============================] - 0s 358us/sample - loss: 1.1927 - acc: 0.5500 - val_loss: 1.4113 - val_acc: 0.5000\n",
      "Epoch 326/1000\n",
      "80/80 [==============================] - 0s 360us/sample - loss: 1.1921 - acc: 0.5500 - val_loss: 1.4285 - val_acc: 0.5500\n",
      "Epoch 327/1000\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 1.1882 - acc: 0.5500 - val_loss: 1.4178 - val_acc: 0.5000\n",
      "Epoch 328/1000\n",
      "80/80 [==============================] - 0s 462us/sample - loss: 1.1906 - acc: 0.5500 - val_loss: 1.4187 - val_acc: 0.5000\n",
      "Epoch 329/1000\n",
      "80/80 [==============================] - 0s 521us/sample - loss: 1.1852 - acc: 0.5500 - val_loss: 1.4078 - val_acc: 0.4500\n",
      "Epoch 330/1000\n",
      "80/80 [==============================] - 0s 519us/sample - loss: 1.1857 - acc: 0.5500 - val_loss: 1.4211 - val_acc: 0.5000\n",
      "Epoch 331/1000\n",
      "80/80 [==============================] - 0s 498us/sample - loss: 1.1824 - acc: 0.5500 - val_loss: 1.4171 - val_acc: 0.5000\n",
      "Epoch 332/1000\n",
      "80/80 [==============================] - 0s 468us/sample - loss: 1.1809 - acc: 0.5625 - val_loss: 1.4314 - val_acc: 0.5000\n",
      "Epoch 333/1000\n",
      "80/80 [==============================] - 0s 485us/sample - loss: 1.1805 - acc: 0.5375 - val_loss: 1.4163 - val_acc: 0.4500\n",
      "Epoch 334/1000\n",
      "80/80 [==============================] - 0s 469us/sample - loss: 1.1784 - acc: 0.5625 - val_loss: 1.4328 - val_acc: 0.5500\n",
      "Epoch 335/1000\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 1.1761 - acc: 0.5625 - val_loss: 1.4344 - val_acc: 0.5500\n",
      "Epoch 336/1000\n",
      "80/80 [==============================] - 0s 428us/sample - loss: 1.1745 - acc: 0.5625 - val_loss: 1.4341 - val_acc: 0.5500\n",
      "Epoch 337/1000\n",
      "80/80 [==============================] - 0s 467us/sample - loss: 1.1732 - acc: 0.5625 - val_loss: 1.4280 - val_acc: 0.5500\n",
      "Epoch 338/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 1.1704 - acc: 0.5500 - val_loss: 1.4268 - val_acc: 0.5500\n",
      "Epoch 339/1000\n",
      "80/80 [==============================] - 0s 497us/sample - loss: 1.1703 - acc: 0.5500 - val_loss: 1.4218 - val_acc: 0.5500\n",
      "Epoch 340/1000\n",
      "80/80 [==============================] - 0s 456us/sample - loss: 1.1714 - acc: 0.5500 - val_loss: 1.4278 - val_acc: 0.5500\n",
      "Epoch 341/1000\n",
      "80/80 [==============================] - 0s 457us/sample - loss: 1.1707 - acc: 0.5625 - val_loss: 1.4196 - val_acc: 0.4500\n",
      "Epoch 342/1000\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 1.1649 - acc: 0.5750 - val_loss: 1.4287 - val_acc: 0.5500\n",
      "Epoch 343/1000\n",
      "80/80 [==============================] - 0s 458us/sample - loss: 1.1641 - acc: 0.5750 - val_loss: 1.4403 - val_acc: 0.5500\n",
      "Epoch 344/1000\n",
      "80/80 [==============================] - 0s 505us/sample - loss: 1.1612 - acc: 0.5625 - val_loss: 1.4293 - val_acc: 0.5500\n",
      "Epoch 345/1000\n",
      "80/80 [==============================] - 0s 490us/sample - loss: 1.1615 - acc: 0.5625 - val_loss: 1.4191 - val_acc: 0.4500\n",
      "Epoch 346/1000\n",
      "80/80 [==============================] - 0s 516us/sample - loss: 1.1576 - acc: 0.5625 - val_loss: 1.4155 - val_acc: 0.5000\n",
      "Epoch 347/1000\n",
      "80/80 [==============================] - 0s 466us/sample - loss: 1.1558 - acc: 0.5625 - val_loss: 1.4110 - val_acc: 0.5000\n",
      "Epoch 348/1000\n",
      "80/80 [==============================] - 0s 445us/sample - loss: 1.1543 - acc: 0.5625 - val_loss: 1.4203 - val_acc: 0.5000\n",
      "Epoch 349/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 1.1541 - acc: 0.5750 - val_loss: 1.4360 - val_acc: 0.5500\n",
      "Epoch 350/1000\n",
      "80/80 [==============================] - 0s 364us/sample - loss: 1.1533 - acc: 0.5625 - val_loss: 1.4114 - val_acc: 0.5000\n",
      "Epoch 351/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 1.1505 - acc: 0.5750 - val_loss: 1.4171 - val_acc: 0.5500\n",
      "Epoch 352/1000\n",
      "80/80 [==============================] - 0s 357us/sample - loss: 1.1484 - acc: 0.5750 - val_loss: 1.4276 - val_acc: 0.5000\n",
      "Epoch 353/1000\n",
      "80/80 [==============================] - 0s 358us/sample - loss: 1.1481 - acc: 0.5625 - val_loss: 1.4255 - val_acc: 0.5000\n",
      "Epoch 354/1000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 1.1485 - acc: 0.5750 - val_loss: 1.4203 - val_acc: 0.5500\n",
      "Epoch 355/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 327us/sample - loss: 1.1446 - acc: 0.5625 - val_loss: 1.4181 - val_acc: 0.5500\n",
      "Epoch 356/1000\n",
      "80/80 [==============================] - 0s 367us/sample - loss: 1.1457 - acc: 0.5625 - val_loss: 1.4164 - val_acc: 0.5000\n",
      "Epoch 357/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 1.1437 - acc: 0.5750 - val_loss: 1.4358 - val_acc: 0.5000\n",
      "Epoch 358/1000\n",
      "80/80 [==============================] - 0s 365us/sample - loss: 1.1390 - acc: 0.5625 - val_loss: 1.4014 - val_acc: 0.5500\n",
      "Epoch 359/1000\n",
      "80/80 [==============================] - 0s 351us/sample - loss: 1.1406 - acc: 0.5750 - val_loss: 1.4193 - val_acc: 0.5500\n",
      "Epoch 360/1000\n",
      "80/80 [==============================] - 0s 373us/sample - loss: 1.1345 - acc: 0.5750 - val_loss: 1.4115 - val_acc: 0.5500\n",
      "Epoch 361/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 1.1328 - acc: 0.5750 - val_loss: 1.4168 - val_acc: 0.5500\n",
      "Epoch 362/1000\n",
      "80/80 [==============================] - 0s 350us/sample - loss: 1.1296 - acc: 0.5750 - val_loss: 1.4133 - val_acc: 0.5500\n",
      "Epoch 363/1000\n",
      "80/80 [==============================] - 0s 363us/sample - loss: 1.1283 - acc: 0.5750 - val_loss: 1.4143 - val_acc: 0.5500\n",
      "Epoch 364/1000\n",
      "80/80 [==============================] - 0s 346us/sample - loss: 1.1277 - acc: 0.5750 - val_loss: 1.4167 - val_acc: 0.5500\n",
      "Epoch 365/1000\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 1.1254 - acc: 0.5750 - val_loss: 1.4166 - val_acc: 0.5500\n",
      "Epoch 366/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 1.1223 - acc: 0.5750 - val_loss: 1.4136 - val_acc: 0.5500\n",
      "Epoch 367/1000\n",
      "80/80 [==============================] - 0s 400us/sample - loss: 1.1202 - acc: 0.5875 - val_loss: 1.4046 - val_acc: 0.5500\n",
      "Epoch 368/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 1.1182 - acc: 0.5750 - val_loss: 1.4165 - val_acc: 0.5500\n",
      "Epoch 369/1000\n",
      "80/80 [==============================] - 0s 398us/sample - loss: 1.1180 - acc: 0.6125 - val_loss: 1.4290 - val_acc: 0.5500\n",
      "Epoch 370/1000\n",
      "80/80 [==============================] - 0s 406us/sample - loss: 1.1143 - acc: 0.5875 - val_loss: 1.3987 - val_acc: 0.5500\n",
      "Epoch 371/1000\n",
      "80/80 [==============================] - 0s 524us/sample - loss: 1.1189 - acc: 0.5875 - val_loss: 1.4143 - val_acc: 0.5500\n",
      "Epoch 372/1000\n",
      "80/80 [==============================] - 0s 390us/sample - loss: 1.1134 - acc: 0.5875 - val_loss: 1.4239 - val_acc: 0.5500\n",
      "Epoch 373/1000\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 1.1150 - acc: 0.5875 - val_loss: 1.4294 - val_acc: 0.5500\n",
      "Epoch 374/1000\n",
      "80/80 [==============================] - 0s 456us/sample - loss: 1.1111 - acc: 0.5875 - val_loss: 1.4141 - val_acc: 0.5500\n",
      "Epoch 375/1000\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 1.1072 - acc: 0.5875 - val_loss: 1.4155 - val_acc: 0.5500\n",
      "Epoch 376/1000\n",
      "80/80 [==============================] - 0s 379us/sample - loss: 1.1045 - acc: 0.5875 - val_loss: 1.4139 - val_acc: 0.5500\n",
      "Epoch 377/1000\n",
      "80/80 [==============================] - 0s 416us/sample - loss: 1.1026 - acc: 0.6000 - val_loss: 1.4269 - val_acc: 0.5500\n",
      "Epoch 378/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 1.1005 - acc: 0.6125 - val_loss: 1.4002 - val_acc: 0.5500\n",
      "Epoch 379/1000\n",
      "80/80 [==============================] - 0s 391us/sample - loss: 1.1009 - acc: 0.6000 - val_loss: 1.4153 - val_acc: 0.5500\n",
      "Epoch 380/1000\n",
      "80/80 [==============================] - 0s 471us/sample - loss: 1.0987 - acc: 0.6125 - val_loss: 1.4344 - val_acc: 0.5500\n",
      "Epoch 381/1000\n",
      "80/80 [==============================] - 0s 464us/sample - loss: 1.0969 - acc: 0.6000 - val_loss: 1.4103 - val_acc: 0.5500\n",
      "Epoch 382/1000\n",
      "80/80 [==============================] - 0s 460us/sample - loss: 1.0946 - acc: 0.6000 - val_loss: 1.4218 - val_acc: 0.5500\n",
      "Epoch 383/1000\n",
      "80/80 [==============================] - 0s 442us/sample - loss: 1.0974 - acc: 0.5875 - val_loss: 1.4276 - val_acc: 0.5500\n",
      "Epoch 384/1000\n",
      "80/80 [==============================] - 0s 489us/sample - loss: 1.0927 - acc: 0.6000 - val_loss: 1.4315 - val_acc: 0.5500\n",
      "Epoch 385/1000\n",
      "80/80 [==============================] - 0s 483us/sample - loss: 1.0883 - acc: 0.6125 - val_loss: 1.4300 - val_acc: 0.5500\n",
      "Epoch 386/1000\n",
      "80/80 [==============================] - 0s 466us/sample - loss: 1.0872 - acc: 0.6000 - val_loss: 1.4263 - val_acc: 0.5500\n",
      "Epoch 387/1000\n",
      "80/80 [==============================] - 0s 424us/sample - loss: 1.0877 - acc: 0.6000 - val_loss: 1.4382 - val_acc: 0.5500\n",
      "Epoch 388/1000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 1.0875 - acc: 0.6000 - val_loss: 1.4203 - val_acc: 0.5500\n",
      "Epoch 389/1000\n",
      "80/80 [==============================] - 0s 419us/sample - loss: 1.0860 - acc: 0.5875 - val_loss: 1.4303 - val_acc: 0.5500\n",
      "Epoch 390/1000\n",
      "80/80 [==============================] - 0s 441us/sample - loss: 1.0811 - acc: 0.6000 - val_loss: 1.4227 - val_acc: 0.5500\n",
      "Epoch 391/1000\n",
      "80/80 [==============================] - 0s 335us/sample - loss: 1.0794 - acc: 0.6125 - val_loss: 1.4350 - val_acc: 0.5500\n",
      "Epoch 392/1000\n",
      "80/80 [==============================] - 0s 348us/sample - loss: 1.0802 - acc: 0.6250 - val_loss: 1.4147 - val_acc: 0.5500\n",
      "Epoch 393/1000\n",
      "80/80 [==============================] - 0s 382us/sample - loss: 1.0766 - acc: 0.6125 - val_loss: 1.4312 - val_acc: 0.5500\n",
      "Epoch 394/1000\n",
      "80/80 [==============================] - 0s 364us/sample - loss: 1.0767 - acc: 0.6125 - val_loss: 1.4433 - val_acc: 0.5500\n",
      "Epoch 395/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 1.0739 - acc: 0.6000 - val_loss: 1.4355 - val_acc: 0.5500\n",
      "Epoch 396/1000\n",
      "80/80 [==============================] - 0s 375us/sample - loss: 1.0733 - acc: 0.6000 - val_loss: 1.4091 - val_acc: 0.6000\n",
      "Epoch 397/1000\n",
      "80/80 [==============================] - 0s 420us/sample - loss: 1.0721 - acc: 0.6125 - val_loss: 1.4237 - val_acc: 0.5500\n",
      "Epoch 398/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 1.0670 - acc: 0.6250 - val_loss: 1.4378 - val_acc: 0.5500\n",
      "Epoch 399/1000\n",
      "80/80 [==============================] - 0s 380us/sample - loss: 1.0675 - acc: 0.6375 - val_loss: 1.4365 - val_acc: 0.5500\n",
      "Epoch 400/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 1.0651 - acc: 0.6125 - val_loss: 1.4199 - val_acc: 0.6000\n",
      "Epoch 401/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 1.0655 - acc: 0.6125 - val_loss: 1.4327 - val_acc: 0.5500\n",
      "Epoch 402/1000\n",
      "80/80 [==============================] - 0s 311us/sample - loss: 1.0628 - acc: 0.6250 - val_loss: 1.4303 - val_acc: 0.6000\n",
      "Epoch 403/1000\n",
      "80/80 [==============================] - 0s 385us/sample - loss: 1.0608 - acc: 0.6500 - val_loss: 1.4324 - val_acc: 0.5500\n",
      "Epoch 404/1000\n",
      "80/80 [==============================] - 0s 353us/sample - loss: 1.0635 - acc: 0.6250 - val_loss: 1.4273 - val_acc: 0.5500\n",
      "Epoch 405/1000\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 1.0585 - acc: 0.6250 - val_loss: 1.4237 - val_acc: 0.6000\n",
      "Epoch 406/1000\n",
      "80/80 [==============================] - 0s 345us/sample - loss: 1.0556 - acc: 0.6250 - val_loss: 1.4177 - val_acc: 0.6000\n",
      "Epoch 407/1000\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 1.0561 - acc: 0.6375 - val_loss: 1.4206 - val_acc: 0.6000\n",
      "Epoch 408/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 1.0530 - acc: 0.6250 - val_loss: 1.4275 - val_acc: 0.5500\n",
      "Epoch 409/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 1.0522 - acc: 0.6125 - val_loss: 1.4159 - val_acc: 0.6000\n",
      "Epoch 410/1000\n",
      "80/80 [==============================] - 0s 342us/sample - loss: 1.0509 - acc: 0.6500 - val_loss: 1.4345 - val_acc: 0.5500\n",
      "Epoch 411/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 1.0481 - acc: 0.6375 - val_loss: 1.4303 - val_acc: 0.5500\n",
      "Epoch 412/1000\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 1.0466 - acc: 0.6375 - val_loss: 1.4308 - val_acc: 0.5500\n",
      "Epoch 413/1000\n",
      "80/80 [==============================] - 0s 346us/sample - loss: 1.0456 - acc: 0.6375 - val_loss: 1.4088 - val_acc: 0.5500\n",
      "Epoch 414/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 360us/sample - loss: 1.0441 - acc: 0.6500 - val_loss: 1.4277 - val_acc: 0.6000\n",
      "Epoch 415/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 1.0456 - acc: 0.6500 - val_loss: 1.4109 - val_acc: 0.5500\n",
      "Epoch 416/1000\n",
      "80/80 [==============================] - 0s 345us/sample - loss: 1.0416 - acc: 0.6500 - val_loss: 1.4258 - val_acc: 0.6000\n",
      "Epoch 417/1000\n",
      "80/80 [==============================] - 0s 364us/sample - loss: 1.0393 - acc: 0.6500 - val_loss: 1.4413 - val_acc: 0.5500\n",
      "Epoch 418/1000\n",
      "80/80 [==============================] - 0s 372us/sample - loss: 1.0394 - acc: 0.6625 - val_loss: 1.4237 - val_acc: 0.6000\n",
      "Epoch 419/1000\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 1.0370 - acc: 0.6500 - val_loss: 1.4346 - val_acc: 0.5500\n",
      "Epoch 420/1000\n",
      "80/80 [==============================] - 0s 364us/sample - loss: 1.0358 - acc: 0.6500 - val_loss: 1.4462 - val_acc: 0.5500\n",
      "Epoch 421/1000\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 1.0345 - acc: 0.6375 - val_loss: 1.4323 - val_acc: 0.6000\n",
      "Epoch 422/1000\n",
      "80/80 [==============================] - 0s 369us/sample - loss: 1.0328 - acc: 0.6375 - val_loss: 1.4336 - val_acc: 0.6000\n",
      "Epoch 423/1000\n",
      "80/80 [==============================] - 0s 359us/sample - loss: 1.0310 - acc: 0.6625 - val_loss: 1.4357 - val_acc: 0.6000\n",
      "Epoch 424/1000\n",
      "80/80 [==============================] - 0s 328us/sample - loss: 1.0302 - acc: 0.6500 - val_loss: 1.4535 - val_acc: 0.5500\n",
      "Epoch 425/1000\n",
      "80/80 [==============================] - 0s 400us/sample - loss: 1.0276 - acc: 0.6500 - val_loss: 1.4303 - val_acc: 0.5500\n",
      "Epoch 426/1000\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 1.0278 - acc: 0.6500 - val_loss: 1.4296 - val_acc: 0.5500\n",
      "Epoch 427/1000\n",
      "80/80 [==============================] - 0s 314us/sample - loss: 1.0265 - acc: 0.6500 - val_loss: 1.4430 - val_acc: 0.6000\n",
      "Epoch 428/1000\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 1.0249 - acc: 0.6625 - val_loss: 1.4269 - val_acc: 0.5500\n",
      "Epoch 429/1000\n",
      "80/80 [==============================] - 0s 403us/sample - loss: 1.0219 - acc: 0.6625 - val_loss: 1.4392 - val_acc: 0.6000\n",
      "Epoch 430/1000\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 1.0207 - acc: 0.6500 - val_loss: 1.4368 - val_acc: 0.6000\n",
      "Epoch 431/1000\n",
      "80/80 [==============================] - 0s 376us/sample - loss: 1.0195 - acc: 0.6625 - val_loss: 1.4349 - val_acc: 0.6000\n",
      "Epoch 432/1000\n",
      "80/80 [==============================] - 0s 400us/sample - loss: 1.0183 - acc: 0.6625 - val_loss: 1.4335 - val_acc: 0.6000\n",
      "Epoch 433/1000\n",
      "80/80 [==============================] - 0s 363us/sample - loss: 1.0200 - acc: 0.6500 - val_loss: 1.4295 - val_acc: 0.5500\n",
      "Epoch 434/1000\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 1.0159 - acc: 0.6625 - val_loss: 1.4315 - val_acc: 0.5500\n",
      "Epoch 435/1000\n",
      "80/80 [==============================] - 0s 364us/sample - loss: 1.0157 - acc: 0.6750 - val_loss: 1.4365 - val_acc: 0.5500\n",
      "Epoch 436/1000\n",
      "80/80 [==============================] - 0s 344us/sample - loss: 1.0140 - acc: 0.6625 - val_loss: 1.4505 - val_acc: 0.6000\n",
      "Epoch 437/1000\n",
      "80/80 [==============================] - 0s 339us/sample - loss: 1.0115 - acc: 0.6500 - val_loss: 1.4441 - val_acc: 0.6000\n",
      "Epoch 438/1000\n",
      "80/80 [==============================] - 0s 287us/sample - loss: 1.0155 - acc: 0.6500 - val_loss: 1.4618 - val_acc: 0.6000\n",
      "Epoch 439/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 1.0107 - acc: 0.6625 - val_loss: 1.4262 - val_acc: 0.5500\n",
      "Epoch 440/1000\n",
      "80/80 [==============================] - 0s 360us/sample - loss: 1.0103 - acc: 0.6500 - val_loss: 1.4474 - val_acc: 0.5500\n",
      "Epoch 441/1000\n",
      "80/80 [==============================] - 0s 327us/sample - loss: 1.0106 - acc: 0.6625 - val_loss: 1.4534 - val_acc: 0.6000\n",
      "Epoch 442/1000\n",
      "80/80 [==============================] - 0s 302us/sample - loss: 1.0091 - acc: 0.6500 - val_loss: 1.4447 - val_acc: 0.5500\n",
      "Epoch 443/1000\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 1.0047 - acc: 0.6625 - val_loss: 1.4422 - val_acc: 0.5500\n",
      "Epoch 444/1000\n",
      "80/80 [==============================] - 0s 312us/sample - loss: 1.0077 - acc: 0.6750 - val_loss: 1.4499 - val_acc: 0.5500\n",
      "Epoch 445/1000\n",
      "80/80 [==============================] - 0s 300us/sample - loss: 1.0073 - acc: 0.6500 - val_loss: 1.4778 - val_acc: 0.6000\n",
      "Epoch 446/1000\n",
      "80/80 [==============================] - 0s 345us/sample - loss: 1.0029 - acc: 0.6750 - val_loss: 1.4550 - val_acc: 0.5500\n",
      "Epoch 447/1000\n",
      "80/80 [==============================] - 0s 334us/sample - loss: 0.9982 - acc: 0.6750 - val_loss: 1.4615 - val_acc: 0.5500\n",
      "Epoch 448/1000\n",
      "80/80 [==============================] - 0s 320us/sample - loss: 0.9974 - acc: 0.6625 - val_loss: 1.4673 - val_acc: 0.6000\n",
      "Epoch 449/1000\n",
      "80/80 [==============================] - 0s 354us/sample - loss: 0.9979 - acc: 0.6250 - val_loss: 1.4599 - val_acc: 0.5500\n",
      "Epoch 450/1000\n",
      "80/80 [==============================] - 0s 360us/sample - loss: 0.9926 - acc: 0.6625 - val_loss: 1.4509 - val_acc: 0.5500\n",
      "Epoch 451/1000\n",
      "80/80 [==============================] - 0s 312us/sample - loss: 0.9973 - acc: 0.6500 - val_loss: 1.4440 - val_acc: 0.5500\n",
      "Epoch 452/1000\n",
      "80/80 [==============================] - 0s 300us/sample - loss: 0.9907 - acc: 0.6750 - val_loss: 1.4456 - val_acc: 0.5500\n",
      "Epoch 453/1000\n",
      "80/80 [==============================] - 0s 286us/sample - loss: 0.9929 - acc: 0.6625 - val_loss: 1.4540 - val_acc: 0.5500\n",
      "Epoch 454/1000\n",
      "80/80 [==============================] - 0s 332us/sample - loss: 0.9882 - acc: 0.6750 - val_loss: 1.4702 - val_acc: 0.5500\n",
      "Epoch 455/1000\n",
      "80/80 [==============================] - 0s 316us/sample - loss: 0.9855 - acc: 0.6750 - val_loss: 1.4460 - val_acc: 0.5500\n",
      "Epoch 456/1000\n",
      "80/80 [==============================] - 0s 291us/sample - loss: 0.9881 - acc: 0.6875 - val_loss: 1.4565 - val_acc: 0.5500\n",
      "Epoch 457/1000\n",
      "80/80 [==============================] - 0s 280us/sample - loss: 0.9851 - acc: 0.6625 - val_loss: 1.4586 - val_acc: 0.5500\n",
      "Epoch 458/1000\n",
      "80/80 [==============================] - 0s 322us/sample - loss: 0.9836 - acc: 0.6750 - val_loss: 1.4918 - val_acc: 0.6000\n",
      "Epoch 459/1000\n",
      "80/80 [==============================] - 0s 314us/sample - loss: 0.9845 - acc: 0.6750 - val_loss: 1.4793 - val_acc: 0.5500\n",
      "Epoch 460/1000\n",
      "80/80 [==============================] - 0s 322us/sample - loss: 0.9817 - acc: 0.6750 - val_loss: 1.4472 - val_acc: 0.5500\n",
      "Epoch 461/1000\n",
      "80/80 [==============================] - 0s 372us/sample - loss: 0.9796 - acc: 0.6750 - val_loss: 1.4555 - val_acc: 0.5500\n",
      "Epoch 462/1000\n",
      "80/80 [==============================] - 0s 334us/sample - loss: 0.9750 - acc: 0.6750 - val_loss: 1.4700 - val_acc: 0.5500\n",
      "Epoch 463/1000\n",
      "80/80 [==============================] - 0s 327us/sample - loss: 0.9761 - acc: 0.6750 - val_loss: 1.4562 - val_acc: 0.5500\n",
      "Epoch 464/1000\n",
      "80/80 [==============================] - 0s 289us/sample - loss: 0.9777 - acc: 0.6500 - val_loss: 1.4635 - val_acc: 0.5500\n",
      "Epoch 465/1000\n",
      "80/80 [==============================] - 0s 351us/sample - loss: 0.9708 - acc: 0.6875 - val_loss: 1.4544 - val_acc: 0.5500\n",
      "Epoch 466/1000\n",
      "80/80 [==============================] - 0s 283us/sample - loss: 0.9712 - acc: 0.6625 - val_loss: 1.4481 - val_acc: 0.5500\n",
      "Epoch 467/1000\n",
      "80/80 [==============================] - 0s 351us/sample - loss: 0.9723 - acc: 0.6750 - val_loss: 1.4740 - val_acc: 0.5500\n",
      "Epoch 468/1000\n",
      "80/80 [==============================] - 0s 361us/sample - loss: 0.9726 - acc: 0.6875 - val_loss: 1.4889 - val_acc: 0.6000\n",
      "Epoch 469/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.9711 - acc: 0.6625 - val_loss: 1.4520 - val_acc: 0.5500\n",
      "Epoch 470/1000\n",
      "80/80 [==============================] - 0s 419us/sample - loss: 0.9652 - acc: 0.7000 - val_loss: 1.4606 - val_acc: 0.5500\n",
      "Epoch 471/1000\n",
      "80/80 [==============================] - 0s 479us/sample - loss: 0.9654 - acc: 0.6750 - val_loss: 1.4540 - val_acc: 0.5500\n",
      "Epoch 472/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 0.9633 - acc: 0.7000 - val_loss: 1.4660 - val_acc: 0.5500\n",
      "Epoch 473/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 439us/sample - loss: 0.9607 - acc: 0.7000 - val_loss: 1.4748 - val_acc: 0.5500\n",
      "Epoch 474/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.9624 - acc: 0.6875 - val_loss: 1.4844 - val_acc: 0.5500\n",
      "Epoch 475/1000\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 0.9591 - acc: 0.6625 - val_loss: 1.5058 - val_acc: 0.6000\n",
      "Epoch 476/1000\n",
      "80/80 [==============================] - 0s 351us/sample - loss: 0.9618 - acc: 0.6875 - val_loss: 1.4626 - val_acc: 0.5500\n",
      "Epoch 477/1000\n",
      "80/80 [==============================] - 0s 401us/sample - loss: 0.9581 - acc: 0.7000 - val_loss: 1.5005 - val_acc: 0.6000\n",
      "Epoch 478/1000\n",
      "80/80 [==============================] - 0s 360us/sample - loss: 0.9567 - acc: 0.7000 - val_loss: 1.4800 - val_acc: 0.5500\n",
      "Epoch 479/1000\n",
      "80/80 [==============================] - 0s 338us/sample - loss: 0.9555 - acc: 0.7125 - val_loss: 1.4667 - val_acc: 0.5500\n",
      "Epoch 480/1000\n",
      "80/80 [==============================] - 0s 361us/sample - loss: 0.9556 - acc: 0.7250 - val_loss: 1.4683 - val_acc: 0.5500\n",
      "Epoch 481/1000\n",
      "80/80 [==============================] - 0s 426us/sample - loss: 0.9543 - acc: 0.7250 - val_loss: 1.4881 - val_acc: 0.5500\n",
      "Epoch 482/1000\n",
      "80/80 [==============================] - 0s 373us/sample - loss: 0.9599 - acc: 0.6875 - val_loss: 1.4905 - val_acc: 0.5500\n",
      "Epoch 483/1000\n",
      "80/80 [==============================] - 0s 379us/sample - loss: 0.9535 - acc: 0.6875 - val_loss: 1.4772 - val_acc: 0.5500\n",
      "Epoch 484/1000\n",
      "80/80 [==============================] - 0s 352us/sample - loss: 0.9488 - acc: 0.7125 - val_loss: 1.4810 - val_acc: 0.5500\n",
      "Epoch 485/1000\n",
      "80/80 [==============================] - 0s 337us/sample - loss: 0.9496 - acc: 0.7000 - val_loss: 1.4702 - val_acc: 0.5500\n",
      "Epoch 486/1000\n",
      "80/80 [==============================] - 0s 412us/sample - loss: 0.9467 - acc: 0.7125 - val_loss: 1.4835 - val_acc: 0.5500\n",
      "Epoch 487/1000\n",
      "80/80 [==============================] - 0s 406us/sample - loss: 0.9464 - acc: 0.7125 - val_loss: 1.4766 - val_acc: 0.5500\n",
      "Epoch 488/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 0.9459 - acc: 0.7250 - val_loss: 1.4963 - val_acc: 0.6000\n",
      "Epoch 489/1000\n",
      "80/80 [==============================] - 0s 392us/sample - loss: 0.9473 - acc: 0.7250 - val_loss: 1.4772 - val_acc: 0.5500\n",
      "Epoch 490/1000\n",
      "80/80 [==============================] - 0s 372us/sample - loss: 0.9411 - acc: 0.7125 - val_loss: 1.4804 - val_acc: 0.5500\n",
      "Epoch 491/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.9424 - acc: 0.7125 - val_loss: 1.4895 - val_acc: 0.5500\n",
      "Epoch 492/1000\n",
      "80/80 [==============================] - 0s 354us/sample - loss: 0.9405 - acc: 0.7125 - val_loss: 1.4639 - val_acc: 0.5500\n",
      "Epoch 493/1000\n",
      "80/80 [==============================] - 0s 353us/sample - loss: 0.9408 - acc: 0.7250 - val_loss: 1.4973 - val_acc: 0.5500\n",
      "Epoch 494/1000\n",
      "80/80 [==============================] - 0s 350us/sample - loss: 0.9410 - acc: 0.7125 - val_loss: 1.5021 - val_acc: 0.5500\n",
      "Epoch 495/1000\n",
      "80/80 [==============================] - 0s 398us/sample - loss: 0.9387 - acc: 0.7125 - val_loss: 1.4776 - val_acc: 0.5500\n",
      "Epoch 496/1000\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.9367 - acc: 0.7250 - val_loss: 1.4998 - val_acc: 0.5500\n",
      "Epoch 497/1000\n",
      "80/80 [==============================] - 0s 390us/sample - loss: 0.9375 - acc: 0.7125 - val_loss: 1.4885 - val_acc: 0.5500\n",
      "Epoch 498/1000\n",
      "80/80 [==============================] - 0s 393us/sample - loss: 0.9335 - acc: 0.7125 - val_loss: 1.4864 - val_acc: 0.5500\n",
      "Epoch 499/1000\n",
      "80/80 [==============================] - 0s 392us/sample - loss: 0.9338 - acc: 0.7250 - val_loss: 1.4882 - val_acc: 0.5500\n",
      "Epoch 500/1000\n",
      "80/80 [==============================] - 0s 379us/sample - loss: 0.9334 - acc: 0.7125 - val_loss: 1.4690 - val_acc: 0.5500\n",
      "Epoch 501/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.9322 - acc: 0.7250 - val_loss: 1.5200 - val_acc: 0.5500\n",
      "Epoch 502/1000\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.9313 - acc: 0.7250 - val_loss: 1.4898 - val_acc: 0.5500\n",
      "Epoch 503/1000\n",
      "80/80 [==============================] - 0s 375us/sample - loss: 0.9301 - acc: 0.7250 - val_loss: 1.4784 - val_acc: 0.5500\n",
      "Epoch 504/1000\n",
      "80/80 [==============================] - 0s 388us/sample - loss: 0.9281 - acc: 0.7250 - val_loss: 1.4800 - val_acc: 0.5500\n",
      "Epoch 505/1000\n",
      "80/80 [==============================] - 0s 376us/sample - loss: 0.9277 - acc: 0.7250 - val_loss: 1.5066 - val_acc: 0.5500\n",
      "Epoch 506/1000\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.9266 - acc: 0.7250 - val_loss: 1.4964 - val_acc: 0.5500\n",
      "Epoch 507/1000\n",
      "80/80 [==============================] - 0s 400us/sample - loss: 0.9273 - acc: 0.7250 - val_loss: 1.4821 - val_acc: 0.5500\n",
      "Epoch 508/1000\n",
      "80/80 [==============================] - 0s 468us/sample - loss: 0.9253 - acc: 0.7250 - val_loss: 1.4972 - val_acc: 0.5500\n",
      "Epoch 509/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.9209 - acc: 0.7250 - val_loss: 1.4788 - val_acc: 0.5500\n",
      "Epoch 510/1000\n",
      "80/80 [==============================] - 0s 332us/sample - loss: 0.9226 - acc: 0.7250 - val_loss: 1.5047 - val_acc: 0.5500\n",
      "Epoch 511/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 0.9210 - acc: 0.7125 - val_loss: 1.4864 - val_acc: 0.5500\n",
      "Epoch 512/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 0.9200 - acc: 0.7125 - val_loss: 1.5198 - val_acc: 0.5500\n",
      "Epoch 513/1000\n",
      "80/80 [==============================] - 0s 355us/sample - loss: 0.9172 - acc: 0.7250 - val_loss: 1.4913 - val_acc: 0.5500\n",
      "Epoch 514/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 0.9178 - acc: 0.7125 - val_loss: 1.5168 - val_acc: 0.5500\n",
      "Epoch 515/1000\n",
      "80/80 [==============================] - 0s 291us/sample - loss: 0.9144 - acc: 0.7250 - val_loss: 1.5223 - val_acc: 0.5500\n",
      "Epoch 516/1000\n",
      "80/80 [==============================] - 0s 321us/sample - loss: 0.9152 - acc: 0.7125 - val_loss: 1.5155 - val_acc: 0.5500\n",
      "Epoch 517/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 0.9146 - acc: 0.7250 - val_loss: 1.5000 - val_acc: 0.5500\n",
      "Epoch 518/1000\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.9137 - acc: 0.7250 - val_loss: 1.4878 - val_acc: 0.5500\n",
      "Epoch 519/1000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.9126 - acc: 0.7250 - val_loss: 1.4996 - val_acc: 0.5500\n",
      "Epoch 520/1000\n",
      "80/80 [==============================] - 0s 357us/sample - loss: 0.9125 - acc: 0.7250 - val_loss: 1.5102 - val_acc: 0.5500\n",
      "Epoch 521/1000\n",
      "80/80 [==============================] - 0s 354us/sample - loss: 0.9117 - acc: 0.7250 - val_loss: 1.4858 - val_acc: 0.5500\n",
      "Epoch 522/1000\n",
      "80/80 [==============================] - 0s 335us/sample - loss: 0.9077 - acc: 0.7250 - val_loss: 1.4900 - val_acc: 0.6000\n",
      "Epoch 523/1000\n",
      "80/80 [==============================] - 0s 357us/sample - loss: 0.9133 - acc: 0.7250 - val_loss: 1.4948 - val_acc: 0.5500\n",
      "Epoch 524/1000\n",
      "80/80 [==============================] - 0s 358us/sample - loss: 0.9077 - acc: 0.7125 - val_loss: 1.5080 - val_acc: 0.5500\n",
      "Epoch 525/1000\n",
      "80/80 [==============================] - 0s 336us/sample - loss: 0.9078 - acc: 0.7250 - val_loss: 1.5184 - val_acc: 0.5500\n",
      "Epoch 526/1000\n",
      "80/80 [==============================] - 0s 335us/sample - loss: 0.9059 - acc: 0.7250 - val_loss: 1.5050 - val_acc: 0.5500\n",
      "Epoch 527/1000\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 0.9043 - acc: 0.7250 - val_loss: 1.5263 - val_acc: 0.5500\n",
      "Epoch 528/1000\n",
      "80/80 [==============================] - 0s 322us/sample - loss: 0.9055 - acc: 0.7250 - val_loss: 1.5249 - val_acc: 0.5500\n",
      "Epoch 529/1000\n",
      "80/80 [==============================] - 0s 319us/sample - loss: 0.9028 - acc: 0.7250 - val_loss: 1.5253 - val_acc: 0.5500\n",
      "Epoch 530/1000\n",
      "80/80 [==============================] - 0s 316us/sample - loss: 0.9005 - acc: 0.7250 - val_loss: 1.5193 - val_acc: 0.5500\n",
      "Epoch 531/1000\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 0.9008 - acc: 0.7250 - val_loss: 1.5280 - val_acc: 0.5500\n",
      "Epoch 532/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 294us/sample - loss: 0.9004 - acc: 0.7250 - val_loss: 1.5224 - val_acc: 0.5500\n",
      "Epoch 533/1000\n",
      "80/80 [==============================] - 0s 296us/sample - loss: 0.8985 - acc: 0.7250 - val_loss: 1.5224 - val_acc: 0.5500\n",
      "Epoch 534/1000\n",
      "80/80 [==============================] - 0s 299us/sample - loss: 0.8974 - acc: 0.7250 - val_loss: 1.5223 - val_acc: 0.5500\n",
      "Epoch 535/1000\n",
      "80/80 [==============================] - 0s 358us/sample - loss: 0.8979 - acc: 0.7250 - val_loss: 1.5354 - val_acc: 0.5500\n",
      "Epoch 536/1000\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 0.8978 - acc: 0.7250 - val_loss: 1.5295 - val_acc: 0.5500\n",
      "Epoch 537/1000\n",
      "80/80 [==============================] - 0s 344us/sample - loss: 0.8964 - acc: 0.7375 - val_loss: 1.5165 - val_acc: 0.5500\n",
      "Epoch 538/1000\n",
      "80/80 [==============================] - 0s 338us/sample - loss: 0.8947 - acc: 0.7250 - val_loss: 1.5208 - val_acc: 0.5500\n",
      "Epoch 539/1000\n",
      "80/80 [==============================] - 0s 313us/sample - loss: 0.8934 - acc: 0.7375 - val_loss: 1.5292 - val_acc: 0.5500\n",
      "Epoch 540/1000\n",
      "80/80 [==============================] - 0s 346us/sample - loss: 0.8968 - acc: 0.7125 - val_loss: 1.5289 - val_acc: 0.5500\n",
      "Epoch 541/1000\n",
      "80/80 [==============================] - 0s 347us/sample - loss: 0.8916 - acc: 0.7125 - val_loss: 1.5477 - val_acc: 0.5500\n",
      "Epoch 542/1000\n",
      "80/80 [==============================] - 0s 333us/sample - loss: 0.8911 - acc: 0.7250 - val_loss: 1.5367 - val_acc: 0.5500\n",
      "Epoch 543/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 0.8898 - acc: 0.7250 - val_loss: 1.5327 - val_acc: 0.5500\n",
      "Epoch 544/1000\n",
      "80/80 [==============================] - 0s 326us/sample - loss: 0.8890 - acc: 0.7125 - val_loss: 1.5511 - val_acc: 0.5500\n",
      "Epoch 545/1000\n",
      "80/80 [==============================] - 0s 357us/sample - loss: 0.8902 - acc: 0.7375 - val_loss: 1.5352 - val_acc: 0.5500\n",
      "Epoch 546/1000\n",
      "80/80 [==============================] - 0s 320us/sample - loss: 0.8878 - acc: 0.7250 - val_loss: 1.5329 - val_acc: 0.5500\n",
      "Epoch 547/1000\n",
      "80/80 [==============================] - 0s 326us/sample - loss: 0.8892 - acc: 0.7375 - val_loss: 1.5329 - val_acc: 0.5500\n",
      "Epoch 548/1000\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.8857 - acc: 0.7375 - val_loss: 1.5459 - val_acc: 0.5500\n",
      "Epoch 549/1000\n",
      "80/80 [==============================] - 0s 337us/sample - loss: 0.8843 - acc: 0.7375 - val_loss: 1.5325 - val_acc: 0.5500\n",
      "Epoch 550/1000\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 0.8860 - acc: 0.7250 - val_loss: 1.5167 - val_acc: 0.5500\n",
      "Epoch 551/1000\n",
      "80/80 [==============================] - 0s 420us/sample - loss: 0.8843 - acc: 0.7250 - val_loss: 1.5307 - val_acc: 0.5500\n",
      "Epoch 552/1000\n",
      "80/80 [==============================] - 0s 401us/sample - loss: 0.8840 - acc: 0.7375 - val_loss: 1.5311 - val_acc: 0.5500\n",
      "Epoch 553/1000\n",
      "80/80 [==============================] - 0s 402us/sample - loss: 0.8828 - acc: 0.7250 - val_loss: 1.5674 - val_acc: 0.5500\n",
      "Epoch 554/1000\n",
      "80/80 [==============================] - 0s 352us/sample - loss: 0.8837 - acc: 0.7250 - val_loss: 1.5364 - val_acc: 0.5500\n",
      "Epoch 555/1000\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 0.8818 - acc: 0.7375 - val_loss: 1.5534 - val_acc: 0.5500\n",
      "Epoch 556/1000\n",
      "80/80 [==============================] - 0s 333us/sample - loss: 0.8792 - acc: 0.7250 - val_loss: 1.5675 - val_acc: 0.5500\n",
      "Epoch 557/1000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 0.8776 - acc: 0.7250 - val_loss: 1.5529 - val_acc: 0.5500\n",
      "Epoch 558/1000\n",
      "80/80 [==============================] - 0s 307us/sample - loss: 0.8785 - acc: 0.7375 - val_loss: 1.5431 - val_acc: 0.5500\n",
      "Epoch 559/1000\n",
      "80/80 [==============================] - 0s 363us/sample - loss: 0.8769 - acc: 0.7375 - val_loss: 1.5443 - val_acc: 0.5500\n",
      "Epoch 560/1000\n",
      "80/80 [==============================] - 0s 318us/sample - loss: 0.8753 - acc: 0.7250 - val_loss: 1.5574 - val_acc: 0.5500\n",
      "Epoch 561/1000\n",
      "80/80 [==============================] - 0s 293us/sample - loss: 0.8753 - acc: 0.7500 - val_loss: 1.5208 - val_acc: 0.6000\n",
      "Epoch 562/1000\n",
      "80/80 [==============================] - 0s 285us/sample - loss: 0.8749 - acc: 0.7375 - val_loss: 1.5560 - val_acc: 0.5500\n",
      "Epoch 563/1000\n",
      "80/80 [==============================] - 0s 334us/sample - loss: 0.8739 - acc: 0.7250 - val_loss: 1.5607 - val_acc: 0.5500\n",
      "Epoch 564/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.8752 - acc: 0.7250 - val_loss: 1.5593 - val_acc: 0.5500\n",
      "Epoch 565/1000\n",
      "80/80 [==============================] - 0s 332us/sample - loss: 0.8715 - acc: 0.7375 - val_loss: 1.5413 - val_acc: 0.5500\n",
      "Epoch 566/1000\n",
      "80/80 [==============================] - 0s 356us/sample - loss: 0.8705 - acc: 0.7375 - val_loss: 1.5580 - val_acc: 0.5500\n",
      "Epoch 567/1000\n",
      "80/80 [==============================] - 0s 382us/sample - loss: 0.8697 - acc: 0.7375 - val_loss: 1.5436 - val_acc: 0.5500\n",
      "Epoch 568/1000\n",
      "80/80 [==============================] - 0s 360us/sample - loss: 0.8720 - acc: 0.7250 - val_loss: 1.5617 - val_acc: 0.5500\n",
      "Epoch 569/1000\n",
      "80/80 [==============================] - 0s 355us/sample - loss: 0.8680 - acc: 0.7375 - val_loss: 1.5559 - val_acc: 0.5500\n",
      "Epoch 570/1000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 0.8680 - acc: 0.7500 - val_loss: 1.5609 - val_acc: 0.5500\n",
      "Epoch 571/1000\n",
      "80/80 [==============================] - 0s 378us/sample - loss: 0.8666 - acc: 0.7250 - val_loss: 1.5514 - val_acc: 0.5500\n",
      "Epoch 572/1000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.8654 - acc: 0.7375 - val_loss: 1.5592 - val_acc: 0.5500\n",
      "Epoch 573/1000\n",
      "80/80 [==============================] - 0s 337us/sample - loss: 0.8657 - acc: 0.7375 - val_loss: 1.5779 - val_acc: 0.5500\n",
      "Epoch 574/1000\n",
      "80/80 [==============================] - 0s 340us/sample - loss: 0.8645 - acc: 0.7375 - val_loss: 1.5554 - val_acc: 0.5500\n",
      "Epoch 575/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.8637 - acc: 0.7250 - val_loss: 1.5636 - val_acc: 0.5500\n",
      "Epoch 576/1000\n",
      "80/80 [==============================] - 0s 298us/sample - loss: 0.8646 - acc: 0.7375 - val_loss: 1.5626 - val_acc: 0.5500\n",
      "Epoch 577/1000\n",
      "80/80 [==============================] - 0s 318us/sample - loss: 0.8624 - acc: 0.7375 - val_loss: 1.5612 - val_acc: 0.5500\n",
      "Epoch 578/1000\n",
      "80/80 [==============================] - 0s 272us/sample - loss: 0.8604 - acc: 0.7375 - val_loss: 1.5679 - val_acc: 0.5500\n",
      "Epoch 579/1000\n",
      "80/80 [==============================] - 0s 406us/sample - loss: 0.8600 - acc: 0.7500 - val_loss: 1.5606 - val_acc: 0.6000\n",
      "Epoch 580/1000\n",
      "80/80 [==============================] - 0s 335us/sample - loss: 0.8612 - acc: 0.7375 - val_loss: 1.5754 - val_acc: 0.5500\n",
      "Epoch 581/1000\n",
      "80/80 [==============================] - 0s 341us/sample - loss: 0.8595 - acc: 0.7250 - val_loss: 1.5932 - val_acc: 0.5500\n",
      "Epoch 582/1000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.8603 - acc: 0.7375 - val_loss: 1.6040 - val_acc: 0.5500\n",
      "Epoch 583/1000\n",
      "80/80 [==============================] - 0s 338us/sample - loss: 0.8582 - acc: 0.7375 - val_loss: 1.5625 - val_acc: 0.5500\n",
      "Epoch 584/1000\n",
      "80/80 [==============================] - 0s 297us/sample - loss: 0.8591 - acc: 0.7375 - val_loss: 1.5723 - val_acc: 0.5500\n",
      "Epoch 585/1000\n",
      "80/80 [==============================] - 0s 341us/sample - loss: 0.8553 - acc: 0.7500 - val_loss: 1.5905 - val_acc: 0.5500\n",
      "Epoch 586/1000\n",
      "80/80 [==============================] - 0s 324us/sample - loss: 0.8570 - acc: 0.7500 - val_loss: 1.5871 - val_acc: 0.5500\n",
      "Epoch 587/1000\n",
      "80/80 [==============================] - 0s 285us/sample - loss: 0.8549 - acc: 0.7375 - val_loss: 1.5882 - val_acc: 0.5500\n",
      "Epoch 588/1000\n",
      "80/80 [==============================] - 0s 329us/sample - loss: 0.8550 - acc: 0.7500 - val_loss: 1.5732 - val_acc: 0.5500\n",
      "Epoch 589/1000\n",
      "80/80 [==============================] - 0s 350us/sample - loss: 0.8546 - acc: 0.7375 - val_loss: 1.5757 - val_acc: 0.5500\n",
      "Epoch 590/1000\n",
      "80/80 [==============================] - 0s 315us/sample - loss: 0.8532 - acc: 0.7500 - val_loss: 1.5835 - val_acc: 0.5500\n",
      "Epoch 591/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 350us/sample - loss: 0.8529 - acc: 0.7625 - val_loss: 1.5774 - val_acc: 0.5500\n",
      "Epoch 592/1000\n",
      "80/80 [==============================] - 0s 297us/sample - loss: 0.8505 - acc: 0.7375 - val_loss: 1.5933 - val_acc: 0.5500\n",
      "Epoch 593/1000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 0.8495 - acc: 0.7375 - val_loss: 1.5684 - val_acc: 0.5500\n",
      "Epoch 594/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.8501 - acc: 0.7625 - val_loss: 1.5888 - val_acc: 0.5500\n",
      "Epoch 595/1000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.8490 - acc: 0.7500 - val_loss: 1.5891 - val_acc: 0.5500\n",
      "Epoch 596/1000\n",
      "80/80 [==============================] - 0s 352us/sample - loss: 0.8507 - acc: 0.7500 - val_loss: 1.5988 - val_acc: 0.5500\n",
      "Epoch 597/1000\n",
      "80/80 [==============================] - 0s 278us/sample - loss: 0.8495 - acc: 0.7500 - val_loss: 1.5527 - val_acc: 0.5500\n",
      "Epoch 598/1000\n",
      "80/80 [==============================] - 0s 353us/sample - loss: 0.8482 - acc: 0.7375 - val_loss: 1.5862 - val_acc: 0.5500\n",
      "Epoch 599/1000\n",
      "80/80 [==============================] - 0s 285us/sample - loss: 0.8478 - acc: 0.7500 - val_loss: 1.5871 - val_acc: 0.5500\n",
      "Epoch 600/1000\n",
      "80/80 [==============================] - 0s 320us/sample - loss: 0.8449 - acc: 0.7375 - val_loss: 1.5967 - val_acc: 0.5500\n",
      "Epoch 601/1000\n",
      "80/80 [==============================] - 0s 327us/sample - loss: 0.8453 - acc: 0.7375 - val_loss: 1.5947 - val_acc: 0.5500\n",
      "Epoch 602/1000\n",
      "80/80 [==============================] - 0s 336us/sample - loss: 0.8441 - acc: 0.7375 - val_loss: 1.6069 - val_acc: 0.5500\n",
      "Epoch 603/1000\n",
      "80/80 [==============================] - 0s 301us/sample - loss: 0.8449 - acc: 0.7500 - val_loss: 1.5968 - val_acc: 0.5500\n",
      "Epoch 604/1000\n",
      "80/80 [==============================] - 0s 380us/sample - loss: 0.8437 - acc: 0.7500 - val_loss: 1.6012 - val_acc: 0.5500\n",
      "Epoch 605/1000\n",
      "80/80 [==============================] - 0s 337us/sample - loss: 0.8418 - acc: 0.7500 - val_loss: 1.6429 - val_acc: 0.6000\n",
      "Epoch 606/1000\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 0.8432 - acc: 0.7500 - val_loss: 1.5967 - val_acc: 0.5500\n",
      "Epoch 607/1000\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 0.8412 - acc: 0.7500 - val_loss: 1.6051 - val_acc: 0.5500\n",
      "Epoch 608/1000\n",
      "80/80 [==============================] - 0s 396us/sample - loss: 0.8403 - acc: 0.7500 - val_loss: 1.5944 - val_acc: 0.5500\n",
      "Epoch 609/1000\n",
      "80/80 [==============================] - 0s 394us/sample - loss: 0.8399 - acc: 0.7375 - val_loss: 1.5971 - val_acc: 0.5500\n",
      "Epoch 610/1000\n",
      "80/80 [==============================] - 0s 385us/sample - loss: 0.8383 - acc: 0.7625 - val_loss: 1.5948 - val_acc: 0.5500\n",
      "Epoch 611/1000\n",
      "80/80 [==============================] - 0s 324us/sample - loss: 0.8383 - acc: 0.7500 - val_loss: 1.6155 - val_acc: 0.5500\n",
      "Epoch 612/1000\n",
      "80/80 [==============================] - 0s 317us/sample - loss: 0.8369 - acc: 0.7625 - val_loss: 1.6034 - val_acc: 0.5500\n",
      "Epoch 613/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 0.8362 - acc: 0.7500 - val_loss: 1.6287 - val_acc: 0.5500\n",
      "Epoch 614/1000\n",
      "80/80 [==============================] - 0s 485us/sample - loss: 0.8351 - acc: 0.7500 - val_loss: 1.6284 - val_acc: 0.5500\n",
      "Epoch 615/1000\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 0.8347 - acc: 0.7500 - val_loss: 1.5935 - val_acc: 0.6000\n",
      "Epoch 616/1000\n",
      "80/80 [==============================] - 0s 466us/sample - loss: 0.8356 - acc: 0.7375 - val_loss: 1.6112 - val_acc: 0.5500\n",
      "Epoch 617/1000\n",
      "80/80 [==============================] - 0s 471us/sample - loss: 0.8359 - acc: 0.7500 - val_loss: 1.6351 - val_acc: 0.5500\n",
      "Epoch 618/1000\n",
      "80/80 [==============================] - 0s 442us/sample - loss: 0.8344 - acc: 0.7375 - val_loss: 1.6277 - val_acc: 0.5500\n",
      "Epoch 619/1000\n",
      "80/80 [==============================] - 0s 420us/sample - loss: 0.8329 - acc: 0.7500 - val_loss: 1.5950 - val_acc: 0.5500\n",
      "Epoch 620/1000\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 0.8321 - acc: 0.7500 - val_loss: 1.5997 - val_acc: 0.5500\n",
      "Epoch 621/1000\n",
      "80/80 [==============================] - 0s 434us/sample - loss: 0.8318 - acc: 0.7500 - val_loss: 1.6094 - val_acc: 0.5500\n",
      "Epoch 622/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 0.8306 - acc: 0.7500 - val_loss: 1.6172 - val_acc: 0.6000\n",
      "Epoch 623/1000\n",
      "80/80 [==============================] - 0s 431us/sample - loss: 0.8302 - acc: 0.7500 - val_loss: 1.6343 - val_acc: 0.5500\n",
      "Epoch 624/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 0.8286 - acc: 0.7500 - val_loss: 1.6071 - val_acc: 0.5500\n",
      "Epoch 625/1000\n",
      "80/80 [==============================] - 0s 408us/sample - loss: 0.8295 - acc: 0.7500 - val_loss: 1.6144 - val_acc: 0.5500\n",
      "Epoch 626/1000\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 0.8284 - acc: 0.7500 - val_loss: 1.6148 - val_acc: 0.5500\n",
      "Epoch 627/1000\n",
      "80/80 [==============================] - 0s 408us/sample - loss: 0.8270 - acc: 0.7625 - val_loss: 1.5946 - val_acc: 0.5500\n",
      "Epoch 628/1000\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.8272 - acc: 0.7375 - val_loss: 1.6429 - val_acc: 0.5500\n",
      "Epoch 629/1000\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.8262 - acc: 0.7500 - val_loss: 1.6443 - val_acc: 0.5500\n",
      "Epoch 630/1000\n",
      "80/80 [==============================] - 0s 449us/sample - loss: 0.8250 - acc: 0.7500 - val_loss: 1.6373 - val_acc: 0.5500\n",
      "Epoch 631/1000\n",
      "80/80 [==============================] - 0s 488us/sample - loss: 0.8253 - acc: 0.7500 - val_loss: 1.6199 - val_acc: 0.5500\n",
      "Epoch 632/1000\n",
      "80/80 [==============================] - 0s 474us/sample - loss: 0.8239 - acc: 0.7500 - val_loss: 1.6360 - val_acc: 0.5500\n",
      "Epoch 633/1000\n",
      "80/80 [==============================] - 0s 439us/sample - loss: 0.8233 - acc: 0.7500 - val_loss: 1.6417 - val_acc: 0.5500\n",
      "Epoch 634/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 0.8236 - acc: 0.7500 - val_loss: 1.6374 - val_acc: 0.5500\n",
      "Epoch 635/1000\n",
      "80/80 [==============================] - 0s 417us/sample - loss: 0.8226 - acc: 0.7500 - val_loss: 1.6412 - val_acc: 0.5500\n",
      "Epoch 636/1000\n",
      "80/80 [==============================] - 0s 416us/sample - loss: 0.8225 - acc: 0.7625 - val_loss: 1.6354 - val_acc: 0.5500\n",
      "Epoch 637/1000\n",
      "80/80 [==============================] - 0s 440us/sample - loss: 0.8224 - acc: 0.7500 - val_loss: 1.6554 - val_acc: 0.5500\n",
      "Epoch 638/1000\n",
      "80/80 [==============================] - 0s 442us/sample - loss: 0.8215 - acc: 0.7500 - val_loss: 1.6489 - val_acc: 0.5500\n",
      "Epoch 639/1000\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 0.8204 - acc: 0.7500 - val_loss: 1.6483 - val_acc: 0.5500\n",
      "Epoch 640/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 0.8184 - acc: 0.7500 - val_loss: 1.6605 - val_acc: 0.5500\n",
      "Epoch 641/1000\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.8183 - acc: 0.7500 - val_loss: 1.6582 - val_acc: 0.5500\n",
      "Epoch 642/1000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.8181 - acc: 0.7500 - val_loss: 1.6467 - val_acc: 0.5500\n",
      "Epoch 643/1000\n",
      "80/80 [==============================] - 0s 402us/sample - loss: 0.8180 - acc: 0.7500 - val_loss: 1.6555 - val_acc: 0.5500\n",
      "Epoch 644/1000\n",
      "80/80 [==============================] - 0s 384us/sample - loss: 0.8163 - acc: 0.7500 - val_loss: 1.6480 - val_acc: 0.5500\n",
      "Epoch 645/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 0.8140 - acc: 0.7500 - val_loss: 1.6170 - val_acc: 0.6000\n",
      "Epoch 646/1000\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 0.8167 - acc: 0.7625 - val_loss: 1.6707 - val_acc: 0.5500\n",
      "Epoch 647/1000\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 0.8144 - acc: 0.7625 - val_loss: 1.6486 - val_acc: 0.5500\n",
      "Epoch 648/1000\n",
      "80/80 [==============================] - 0s 482us/sample - loss: 0.8150 - acc: 0.7500 - val_loss: 1.6755 - val_acc: 0.5500\n",
      "Epoch 649/1000\n",
      "80/80 [==============================] - 0s 465us/sample - loss: 0.8130 - acc: 0.7500 - val_loss: 1.6760 - val_acc: 0.5500\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 521us/sample - loss: 0.8129 - acc: 0.7500 - val_loss: 1.6525 - val_acc: 0.5500\n",
      "Epoch 651/1000\n",
      "80/80 [==============================] - 0s 522us/sample - loss: 0.8123 - acc: 0.7500 - val_loss: 1.6819 - val_acc: 0.5500\n",
      "Epoch 652/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 0.8131 - acc: 0.7500 - val_loss: 1.6714 - val_acc: 0.5500\n",
      "Epoch 653/1000\n",
      "80/80 [==============================] - 0s 436us/sample - loss: 0.8115 - acc: 0.7500 - val_loss: 1.6677 - val_acc: 0.5500\n",
      "Epoch 654/1000\n",
      "80/80 [==============================] - 0s 489us/sample - loss: 0.8112 - acc: 0.7500 - val_loss: 1.6749 - val_acc: 0.5500\n",
      "Epoch 655/1000\n",
      "80/80 [==============================] - 0s 532us/sample - loss: 0.8095 - acc: 0.7500 - val_loss: 1.6764 - val_acc: 0.5500\n",
      "Epoch 656/1000\n",
      "80/80 [==============================] - 0s 556us/sample - loss: 0.8104 - acc: 0.7500 - val_loss: 1.6414 - val_acc: 0.5500\n",
      "Epoch 657/1000\n",
      "80/80 [==============================] - 0s 460us/sample - loss: 0.8100 - acc: 0.7500 - val_loss: 1.6808 - val_acc: 0.5500\n",
      "Epoch 658/1000\n",
      "80/80 [==============================] - 0s 536us/sample - loss: 0.8086 - acc: 0.7500 - val_loss: 1.6582 - val_acc: 0.5500\n",
      "Epoch 659/1000\n",
      "80/80 [==============================] - 0s 716us/sample - loss: 0.8088 - acc: 0.7500 - val_loss: 1.6801 - val_acc: 0.5500\n",
      "Epoch 660/1000\n",
      "80/80 [==============================] - 0s 602us/sample - loss: 0.8066 - acc: 0.7625 - val_loss: 1.6420 - val_acc: 0.5500\n",
      "Epoch 661/1000\n",
      "80/80 [==============================] - 0s 506us/sample - loss: 0.8063 - acc: 0.7500 - val_loss: 1.6702 - val_acc: 0.5500\n",
      "Epoch 662/1000\n",
      "80/80 [==============================] - 0s 342us/sample - loss: 0.8063 - acc: 0.7625 - val_loss: 1.6829 - val_acc: 0.5500\n",
      "Epoch 663/1000\n",
      "80/80 [==============================] - 0s 410us/sample - loss: 0.8063 - acc: 0.7625 - val_loss: 1.6694 - val_acc: 0.5500\n",
      "Epoch 664/1000\n",
      "80/80 [==============================] - 0s 320us/sample - loss: 0.8066 - acc: 0.7500 - val_loss: 1.6453 - val_acc: 0.6000\n",
      "Epoch 665/1000\n",
      "80/80 [==============================] - 0s 429us/sample - loss: 0.8040 - acc: 0.7625 - val_loss: 1.6478 - val_acc: 0.5500\n",
      "Epoch 666/1000\n",
      "80/80 [==============================] - 0s 450us/sample - loss: 0.8050 - acc: 0.7500 - val_loss: 1.6920 - val_acc: 0.5500\n",
      "Epoch 667/1000\n",
      "80/80 [==============================] - 0s 437us/sample - loss: 0.8020 - acc: 0.7500 - val_loss: 1.6465 - val_acc: 0.6000\n",
      "Epoch 668/1000\n",
      "80/80 [==============================] - 0s 388us/sample - loss: 0.8038 - acc: 0.7500 - val_loss: 1.6658 - val_acc: 0.5500\n",
      "Epoch 669/1000\n",
      "80/80 [==============================] - 0s 458us/sample - loss: 0.8034 - acc: 0.7625 - val_loss: 1.6719 - val_acc: 0.5500\n",
      "Epoch 670/1000\n",
      "80/80 [==============================] - 0s 437us/sample - loss: 0.8017 - acc: 0.7500 - val_loss: 1.6969 - val_acc: 0.5500\n",
      "Epoch 671/1000\n",
      "80/80 [==============================] - 0s 419us/sample - loss: 0.8004 - acc: 0.7500 - val_loss: 1.6676 - val_acc: 0.5500\n",
      "Epoch 672/1000\n",
      "80/80 [==============================] - 0s 435us/sample - loss: 0.7999 - acc: 0.7500 - val_loss: 1.6585 - val_acc: 0.5500\n",
      "Epoch 673/1000\n",
      "80/80 [==============================] - 0s 472us/sample - loss: 0.8005 - acc: 0.7500 - val_loss: 1.6756 - val_acc: 0.5500\n",
      "Epoch 674/1000\n",
      "80/80 [==============================] - 0s 456us/sample - loss: 0.7979 - acc: 0.7750 - val_loss: 1.6920 - val_acc: 0.5500\n",
      "Epoch 675/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 0.7981 - acc: 0.7625 - val_loss: 1.6963 - val_acc: 0.5500\n",
      "Epoch 676/1000\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 0.7977 - acc: 0.7625 - val_loss: 1.6893 - val_acc: 0.5500\n",
      "Epoch 677/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 0.7973 - acc: 0.7625 - val_loss: 1.6827 - val_acc: 0.5500\n",
      "Epoch 678/1000\n",
      "80/80 [==============================] - 0s 445us/sample - loss: 0.7960 - acc: 0.7750 - val_loss: 1.6868 - val_acc: 0.5500\n",
      "Epoch 679/1000\n",
      "80/80 [==============================] - 0s 457us/sample - loss: 0.7959 - acc: 0.7750 - val_loss: 1.7019 - val_acc: 0.5500\n",
      "Epoch 680/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 0.7947 - acc: 0.7625 - val_loss: 1.7035 - val_acc: 0.5500\n",
      "Epoch 681/1000\n",
      "80/80 [==============================] - 0s 426us/sample - loss: 0.7951 - acc: 0.7625 - val_loss: 1.6974 - val_acc: 0.5500\n",
      "Epoch 682/1000\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.7953 - acc: 0.7750 - val_loss: 1.7039 - val_acc: 0.5500\n",
      "Epoch 683/1000\n",
      "80/80 [==============================] - 0s 440us/sample - loss: 0.7928 - acc: 0.7750 - val_loss: 1.7160 - val_acc: 0.5500\n",
      "Epoch 684/1000\n",
      "80/80 [==============================] - 0s 459us/sample - loss: 0.7941 - acc: 0.7625 - val_loss: 1.7022 - val_acc: 0.5500\n",
      "Epoch 685/1000\n",
      "80/80 [==============================] - 0s 469us/sample - loss: 0.7940 - acc: 0.7750 - val_loss: 1.6916 - val_acc: 0.5500\n",
      "Epoch 686/1000\n",
      "80/80 [==============================] - 0s 513us/sample - loss: 0.7923 - acc: 0.7750 - val_loss: 1.7018 - val_acc: 0.5500\n",
      "Epoch 687/1000\n",
      "80/80 [==============================] - 0s 472us/sample - loss: 0.7917 - acc: 0.7625 - val_loss: 1.7136 - val_acc: 0.5500\n",
      "Epoch 688/1000\n",
      "80/80 [==============================] - 0s 498us/sample - loss: 0.7900 - acc: 0.7750 - val_loss: 1.7100 - val_acc: 0.5500\n",
      "Epoch 689/1000\n",
      "80/80 [==============================] - 0s 442us/sample - loss: 0.7908 - acc: 0.7750 - val_loss: 1.6920 - val_acc: 0.5500\n",
      "Epoch 690/1000\n",
      "80/80 [==============================] - 0s 480us/sample - loss: 0.7913 - acc: 0.7750 - val_loss: 1.7011 - val_acc: 0.5500\n",
      "Epoch 691/1000\n",
      "80/80 [==============================] - 0s 411us/sample - loss: 0.7890 - acc: 0.7750 - val_loss: 1.7094 - val_acc: 0.5500\n",
      "Epoch 692/1000\n",
      "80/80 [==============================] - 0s 455us/sample - loss: 0.7893 - acc: 0.7750 - val_loss: 1.7126 - val_acc: 0.5500\n",
      "Epoch 693/1000\n",
      "80/80 [==============================] - 0s 572us/sample - loss: 0.7874 - acc: 0.7750 - val_loss: 1.7021 - val_acc: 0.5500\n",
      "Epoch 694/1000\n",
      "80/80 [==============================] - 0s 578us/sample - loss: 0.7893 - acc: 0.7625 - val_loss: 1.6960 - val_acc: 0.5500\n",
      "Epoch 695/1000\n",
      "80/80 [==============================] - 0s 467us/sample - loss: 0.7872 - acc: 0.7625 - val_loss: 1.7080 - val_acc: 0.5500\n",
      "Epoch 696/1000\n",
      "80/80 [==============================] - 0s 388us/sample - loss: 0.7877 - acc: 0.7625 - val_loss: 1.7262 - val_acc: 0.5500\n",
      "Epoch 697/1000\n",
      "80/80 [==============================] - 0s 389us/sample - loss: 0.7867 - acc: 0.7750 - val_loss: 1.7054 - val_acc: 0.5500\n",
      "Epoch 698/1000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 0.7865 - acc: 0.7750 - val_loss: 1.7359 - val_acc: 0.5500\n",
      "Epoch 699/1000\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.7863 - acc: 0.7750 - val_loss: 1.7024 - val_acc: 0.5500\n",
      "Epoch 700/1000\n",
      "80/80 [==============================] - 0s 435us/sample - loss: 0.7841 - acc: 0.7750 - val_loss: 1.7239 - val_acc: 0.5500\n",
      "Epoch 701/1000\n",
      "80/80 [==============================] - 0s 382us/sample - loss: 0.7846 - acc: 0.7750 - val_loss: 1.7354 - val_acc: 0.5000\n",
      "Epoch 702/1000\n",
      "80/80 [==============================] - 0s 335us/sample - loss: 0.7833 - acc: 0.7750 - val_loss: 1.7165 - val_acc: 0.5500\n",
      "Epoch 703/1000\n",
      "80/80 [==============================] - 0s 365us/sample - loss: 0.7833 - acc: 0.7750 - val_loss: 1.7187 - val_acc: 0.5500\n",
      "Epoch 704/1000\n",
      "80/80 [==============================] - 0s 393us/sample - loss: 0.7822 - acc: 0.7750 - val_loss: 1.7271 - val_acc: 0.5500\n",
      "Epoch 705/1000\n",
      "80/80 [==============================] - 0s 326us/sample - loss: 0.7814 - acc: 0.7750 - val_loss: 1.7215 - val_acc: 0.5500\n",
      "Epoch 706/1000\n",
      "80/80 [==============================] - 0s 339us/sample - loss: 0.7806 - acc: 0.7750 - val_loss: 1.7229 - val_acc: 0.5500\n",
      "Epoch 707/1000\n",
      "80/80 [==============================] - 0s 433us/sample - loss: 0.7817 - acc: 0.7750 - val_loss: 1.7151 - val_acc: 0.5500\n",
      "Epoch 708/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 0.7810 - acc: 0.7750 - val_loss: 1.7202 - val_acc: 0.6000\n",
      "Epoch 709/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 384us/sample - loss: 0.7804 - acc: 0.7750 - val_loss: 1.7305 - val_acc: 0.5500\n",
      "Epoch 710/1000\n",
      "80/80 [==============================] - 0s 354us/sample - loss: 0.7787 - acc: 0.7750 - val_loss: 1.7439 - val_acc: 0.5000\n",
      "Epoch 711/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 0.7772 - acc: 0.7750 - val_loss: 1.7270 - val_acc: 0.5500\n",
      "Epoch 712/1000\n",
      "80/80 [==============================] - 0s 338us/sample - loss: 0.7787 - acc: 0.7750 - val_loss: 1.7650 - val_acc: 0.5000\n",
      "Epoch 713/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 0.7778 - acc: 0.7750 - val_loss: 1.7276 - val_acc: 0.5500\n",
      "Epoch 714/1000\n",
      "80/80 [==============================] - 0s 284us/sample - loss: 0.7767 - acc: 0.7750 - val_loss: 1.7112 - val_acc: 0.5500\n",
      "Epoch 715/1000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 0.7766 - acc: 0.7750 - val_loss: 1.7410 - val_acc: 0.5500\n",
      "Epoch 716/1000\n",
      "80/80 [==============================] - 0s 332us/sample - loss: 0.7760 - acc: 0.7750 - val_loss: 1.7687 - val_acc: 0.5000\n",
      "Epoch 717/1000\n",
      "80/80 [==============================] - 0s 343us/sample - loss: 0.7759 - acc: 0.7750 - val_loss: 1.7888 - val_acc: 0.5500\n",
      "Epoch 718/1000\n",
      "80/80 [==============================] - 0s 310us/sample - loss: 0.7761 - acc: 0.7750 - val_loss: 1.7670 - val_acc: 0.5000\n",
      "Epoch 719/1000\n",
      "80/80 [==============================] - 0s 379us/sample - loss: 0.7746 - acc: 0.7750 - val_loss: 1.7575 - val_acc: 0.5000\n",
      "Epoch 720/1000\n",
      "80/80 [==============================] - 0s 277us/sample - loss: 0.7735 - acc: 0.7750 - val_loss: 1.7422 - val_acc: 0.5500\n",
      "Epoch 721/1000\n",
      "80/80 [==============================] - 0s 296us/sample - loss: 0.7733 - acc: 0.7750 - val_loss: 1.7423 - val_acc: 0.5500\n",
      "Epoch 722/1000\n",
      "80/80 [==============================] - 0s 326us/sample - loss: 0.7729 - acc: 0.7750 - val_loss: 1.7561 - val_acc: 0.5000\n",
      "Epoch 723/1000\n",
      "80/80 [==============================] - 0s 346us/sample - loss: 0.7728 - acc: 0.7750 - val_loss: 1.7442 - val_acc: 0.5500\n",
      "Epoch 724/1000\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 0.7732 - acc: 0.7750 - val_loss: 1.7345 - val_acc: 0.5500\n",
      "Epoch 725/1000\n",
      "80/80 [==============================] - 0s 319us/sample - loss: 0.7717 - acc: 0.7750 - val_loss: 1.7571 - val_acc: 0.5000\n",
      "Epoch 726/1000\n",
      "80/80 [==============================] - 0s 301us/sample - loss: 0.7702 - acc: 0.7750 - val_loss: 1.7461 - val_acc: 0.5500\n",
      "Epoch 727/1000\n",
      "80/80 [==============================] - 0s 319us/sample - loss: 0.7713 - acc: 0.7750 - val_loss: 1.7514 - val_acc: 0.5000\n",
      "Epoch 728/1000\n",
      "80/80 [==============================] - 0s 297us/sample - loss: 0.7695 - acc: 0.7750 - val_loss: 1.7416 - val_acc: 0.5500\n",
      "Epoch 729/1000\n",
      "80/80 [==============================] - 0s 293us/sample - loss: 0.7697 - acc: 0.7750 - val_loss: 1.7353 - val_acc: 0.5500\n",
      "Epoch 730/1000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 0.7690 - acc: 0.7750 - val_loss: 1.7590 - val_acc: 0.5000\n",
      "Epoch 731/1000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.7689 - acc: 0.7750 - val_loss: 1.7251 - val_acc: 0.5500\n",
      "Epoch 732/1000\n",
      "80/80 [==============================] - 0s 356us/sample - loss: 0.7691 - acc: 0.7750 - val_loss: 1.7634 - val_acc: 0.5000\n",
      "Epoch 733/1000\n",
      "80/80 [==============================] - 0s 290us/sample - loss: 0.7678 - acc: 0.7750 - val_loss: 1.7874 - val_acc: 0.5000\n",
      "Epoch 734/1000\n",
      "80/80 [==============================] - 0s 351us/sample - loss: 0.7666 - acc: 0.7750 - val_loss: 1.7830 - val_acc: 0.5000\n",
      "Epoch 735/1000\n",
      "80/80 [==============================] - 0s 294us/sample - loss: 0.7663 - acc: 0.7750 - val_loss: 1.7828 - val_acc: 0.5000\n",
      "Epoch 736/1000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 0.7661 - acc: 0.7750 - val_loss: 1.7722 - val_acc: 0.5000\n",
      "Epoch 737/1000\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.7653 - acc: 0.7750 - val_loss: 1.7722 - val_acc: 0.5000\n",
      "Epoch 738/1000\n",
      "80/80 [==============================] - 0s 299us/sample - loss: 0.7660 - acc: 0.7875 - val_loss: 1.7836 - val_acc: 0.5000\n",
      "Epoch 739/1000\n",
      "80/80 [==============================] - 0s 315us/sample - loss: 0.7648 - acc: 0.7750 - val_loss: 1.7630 - val_acc: 0.5000\n",
      "Epoch 740/1000\n",
      "80/80 [==============================] - 0s 327us/sample - loss: 0.7641 - acc: 0.7750 - val_loss: 1.7774 - val_acc: 0.5000\n",
      "Epoch 741/1000\n",
      "80/80 [==============================] - 0s 328us/sample - loss: 0.7645 - acc: 0.7750 - val_loss: 1.7651 - val_acc: 0.5000\n",
      "Epoch 742/1000\n",
      "80/80 [==============================] - 0s 379us/sample - loss: 0.7632 - acc: 0.7750 - val_loss: 1.7767 - val_acc: 0.5000\n",
      "Epoch 743/1000\n",
      "80/80 [==============================] - 0s 351us/sample - loss: 0.7634 - acc: 0.7750 - val_loss: 1.7655 - val_acc: 0.5500\n",
      "Epoch 744/1000\n",
      "80/80 [==============================] - 0s 324us/sample - loss: 0.7625 - acc: 0.7750 - val_loss: 1.7950 - val_acc: 0.5000\n",
      "Epoch 745/1000\n",
      "80/80 [==============================] - 0s 349us/sample - loss: 0.7612 - acc: 0.7750 - val_loss: 1.7883 - val_acc: 0.5000\n",
      "Epoch 746/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 0.7614 - acc: 0.7750 - val_loss: 1.7593 - val_acc: 0.6000\n",
      "Epoch 747/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 0.7608 - acc: 0.7750 - val_loss: 1.7978 - val_acc: 0.5000\n",
      "Epoch 748/1000\n",
      "80/80 [==============================] - 0s 437us/sample - loss: 0.7590 - acc: 0.7750 - val_loss: 1.7768 - val_acc: 0.5000\n",
      "Epoch 749/1000\n",
      "80/80 [==============================] - 0s 452us/sample - loss: 0.7590 - acc: 0.7875 - val_loss: 1.7807 - val_acc: 0.5000\n",
      "Epoch 750/1000\n",
      "80/80 [==============================] - 0s 470us/sample - loss: 0.7595 - acc: 0.7875 - val_loss: 1.7725 - val_acc: 0.5000\n",
      "Epoch 751/1000\n",
      "80/80 [==============================] - 0s 408us/sample - loss: 0.7587 - acc: 0.7750 - val_loss: 1.8156 - val_acc: 0.5000\n",
      "Epoch 752/1000\n",
      "80/80 [==============================] - 0s 380us/sample - loss: 0.7579 - acc: 0.7750 - val_loss: 1.8108 - val_acc: 0.5000\n",
      "Epoch 753/1000\n",
      "80/80 [==============================] - 0s 450us/sample - loss: 0.7583 - acc: 0.7875 - val_loss: 1.7868 - val_acc: 0.5000\n",
      "Epoch 754/1000\n",
      "80/80 [==============================] - 0s 490us/sample - loss: 0.7581 - acc: 0.7750 - val_loss: 1.7903 - val_acc: 0.5000\n",
      "Epoch 755/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 0.7562 - acc: 0.7750 - val_loss: 1.7970 - val_acc: 0.5000\n",
      "Epoch 756/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 0.7562 - acc: 0.7750 - val_loss: 1.8154 - val_acc: 0.5000\n",
      "Epoch 757/1000\n",
      "80/80 [==============================] - 0s 345us/sample - loss: 0.7551 - acc: 0.7750 - val_loss: 1.7996 - val_acc: 0.5000\n",
      "Epoch 758/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 0.7551 - acc: 0.7750 - val_loss: 1.7773 - val_acc: 0.5500\n",
      "Epoch 759/1000\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.7544 - acc: 0.7750 - val_loss: 1.8024 - val_acc: 0.5000\n",
      "Epoch 760/1000\n",
      "80/80 [==============================] - 0s 475us/sample - loss: 0.7537 - acc: 0.7875 - val_loss: 1.8160 - val_acc: 0.5000\n",
      "Epoch 761/1000\n",
      "80/80 [==============================] - 0s 499us/sample - loss: 0.7540 - acc: 0.7750 - val_loss: 1.8270 - val_acc: 0.5000\n",
      "Epoch 762/1000\n",
      "80/80 [==============================] - 0s 485us/sample - loss: 0.7545 - acc: 0.7750 - val_loss: 1.8054 - val_acc: 0.5000\n",
      "Epoch 763/1000\n",
      "80/80 [==============================] - 0s 432us/sample - loss: 0.7523 - acc: 0.7750 - val_loss: 1.8251 - val_acc: 0.5000\n",
      "Epoch 764/1000\n",
      "80/80 [==============================] - 0s 353us/sample - loss: 0.7523 - acc: 0.7750 - val_loss: 1.8037 - val_acc: 0.5000\n",
      "Epoch 765/1000\n",
      "80/80 [==============================] - 0s 558us/sample - loss: 0.7523 - acc: 0.7750 - val_loss: 1.8202 - val_acc: 0.5000\n",
      "Epoch 766/1000\n",
      "80/80 [==============================] - 0s 477us/sample - loss: 0.7515 - acc: 0.7750 - val_loss: 1.8415 - val_acc: 0.5000\n",
      "Epoch 767/1000\n",
      "80/80 [==============================] - 0s 558us/sample - loss: 0.7504 - acc: 0.7875 - val_loss: 1.7965 - val_acc: 0.5000\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 456us/sample - loss: 0.7511 - acc: 0.7750 - val_loss: 1.8164 - val_acc: 0.5000\n",
      "Epoch 769/1000\n",
      "80/80 [==============================] - 0s 413us/sample - loss: 0.7505 - acc: 0.7750 - val_loss: 1.8054 - val_acc: 0.5000\n",
      "Epoch 770/1000\n",
      "80/80 [==============================] - 0s 455us/sample - loss: 0.7491 - acc: 0.7750 - val_loss: 1.8267 - val_acc: 0.5000\n",
      "Epoch 771/1000\n",
      "80/80 [==============================] - 0s 390us/sample - loss: 0.7496 - acc: 0.7750 - val_loss: 1.8307 - val_acc: 0.5000\n",
      "Epoch 772/1000\n",
      "80/80 [==============================] - 0s 448us/sample - loss: 0.7481 - acc: 0.7875 - val_loss: 1.8244 - val_acc: 0.5000\n",
      "Epoch 773/1000\n",
      "80/80 [==============================] - 0s 456us/sample - loss: 0.7484 - acc: 0.7750 - val_loss: 1.8256 - val_acc: 0.5000\n",
      "Epoch 774/1000\n",
      "80/80 [==============================] - 0s 516us/sample - loss: 0.7486 - acc: 0.7750 - val_loss: 1.8316 - val_acc: 0.5000\n",
      "Epoch 775/1000\n",
      "80/80 [==============================] - 0s 481us/sample - loss: 0.7471 - acc: 0.7875 - val_loss: 1.8386 - val_acc: 0.5000\n",
      "Epoch 776/1000\n",
      "80/80 [==============================] - 0s 457us/sample - loss: 0.7466 - acc: 0.7750 - val_loss: 1.8394 - val_acc: 0.5000\n",
      "Epoch 777/1000\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.7461 - acc: 0.7750 - val_loss: 1.8404 - val_acc: 0.5000\n",
      "Epoch 778/1000\n",
      "80/80 [==============================] - 0s 460us/sample - loss: 0.7465 - acc: 0.7750 - val_loss: 1.8137 - val_acc: 0.5000\n",
      "Epoch 779/1000\n",
      "80/80 [==============================] - 0s 478us/sample - loss: 0.7458 - acc: 0.7875 - val_loss: 1.8531 - val_acc: 0.5000\n",
      "Epoch 780/1000\n",
      "80/80 [==============================] - 0s 450us/sample - loss: 0.7457 - acc: 0.7875 - val_loss: 1.8351 - val_acc: 0.5000\n",
      "Epoch 781/1000\n",
      "80/80 [==============================] - 0s 453us/sample - loss: 0.7441 - acc: 0.7875 - val_loss: 1.8257 - val_acc: 0.5500\n",
      "Epoch 782/1000\n",
      "80/80 [==============================] - 0s 391us/sample - loss: 0.7450 - acc: 0.7875 - val_loss: 1.8380 - val_acc: 0.5000\n",
      "Epoch 783/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 0.7439 - acc: 0.7750 - val_loss: 1.8392 - val_acc: 0.5000\n",
      "Epoch 784/1000\n",
      "80/80 [==============================] - 0s 415us/sample - loss: 0.7432 - acc: 0.7750 - val_loss: 1.8533 - val_acc: 0.5000\n",
      "Epoch 785/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 0.7435 - acc: 0.7750 - val_loss: 1.8330 - val_acc: 0.5000\n",
      "Epoch 786/1000\n",
      "80/80 [==============================] - 0s 428us/sample - loss: 0.7437 - acc: 0.7875 - val_loss: 1.8351 - val_acc: 0.5000\n",
      "Epoch 787/1000\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 0.7416 - acc: 0.7750 - val_loss: 1.8691 - val_acc: 0.5000\n",
      "Epoch 788/1000\n",
      "80/80 [==============================] - 0s 440us/sample - loss: 0.7415 - acc: 0.7750 - val_loss: 1.8499 - val_acc: 0.5000\n",
      "Epoch 789/1000\n",
      "80/80 [==============================] - 0s 418us/sample - loss: 0.7417 - acc: 0.7750 - val_loss: 1.8288 - val_acc: 0.5000\n",
      "Epoch 790/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 0.7408 - acc: 0.7750 - val_loss: 1.8363 - val_acc: 0.5000\n",
      "Epoch 791/1000\n",
      "80/80 [==============================] - 0s 447us/sample - loss: 0.7392 - acc: 0.7750 - val_loss: 1.8460 - val_acc: 0.5500\n",
      "Epoch 792/1000\n",
      "80/80 [==============================] - 0s 413us/sample - loss: 0.7391 - acc: 0.7750 - val_loss: 1.8537 - val_acc: 0.5000\n",
      "Epoch 793/1000\n",
      "80/80 [==============================] - 0s 340us/sample - loss: 0.7396 - acc: 0.7750 - val_loss: 1.8777 - val_acc: 0.5000\n",
      "Epoch 794/1000\n",
      "80/80 [==============================] - 0s 359us/sample - loss: 0.7384 - acc: 0.7875 - val_loss: 1.8634 - val_acc: 0.5000\n",
      "Epoch 795/1000\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 0.7383 - acc: 0.7750 - val_loss: 1.8708 - val_acc: 0.5000\n",
      "Epoch 796/1000\n",
      "80/80 [==============================] - 0s 398us/sample - loss: 0.7380 - acc: 0.7750 - val_loss: 1.8438 - val_acc: 0.5000\n",
      "Epoch 797/1000\n",
      "80/80 [==============================] - 0s 410us/sample - loss: 0.7376 - acc: 0.7875 - val_loss: 1.8436 - val_acc: 0.5000\n",
      "Epoch 798/1000\n",
      "80/80 [==============================] - 0s 413us/sample - loss: 0.7372 - acc: 0.7750 - val_loss: 1.8561 - val_acc: 0.5000\n",
      "Epoch 799/1000\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.7361 - acc: 0.7875 - val_loss: 1.8526 - val_acc: 0.5000\n",
      "Epoch 800/1000\n",
      "80/80 [==============================] - 0s 428us/sample - loss: 0.7370 - acc: 0.7750 - val_loss: 1.8511 - val_acc: 0.5000\n",
      "Epoch 801/1000\n",
      "80/80 [==============================] - 0s 382us/sample - loss: 0.7354 - acc: 0.7875 - val_loss: 1.8573 - val_acc: 0.5000\n",
      "Epoch 802/1000\n",
      "80/80 [==============================] - 0s 425us/sample - loss: 0.7351 - acc: 0.7750 - val_loss: 1.8206 - val_acc: 0.5000\n",
      "Epoch 803/1000\n",
      "80/80 [==============================] - 0s 400us/sample - loss: 0.7356 - acc: 0.7875 - val_loss: 1.8655 - val_acc: 0.5000\n",
      "Epoch 804/1000\n",
      "80/80 [==============================] - 0s 377us/sample - loss: 0.7345 - acc: 0.7750 - val_loss: 1.8911 - val_acc: 0.5000\n",
      "Epoch 805/1000\n",
      "80/80 [==============================] - 0s 421us/sample - loss: 0.7346 - acc: 0.7750 - val_loss: 1.8724 - val_acc: 0.5000\n",
      "Epoch 806/1000\n",
      "80/80 [==============================] - 0s 391us/sample - loss: 0.7338 - acc: 0.7875 - val_loss: 1.8831 - val_acc: 0.5000\n",
      "Epoch 807/1000\n",
      "80/80 [==============================] - 0s 482us/sample - loss: 0.7335 - acc: 0.7875 - val_loss: 1.8778 - val_acc: 0.5000\n",
      "Epoch 808/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 0.7329 - acc: 0.7875 - val_loss: 1.8622 - val_acc: 0.5000\n",
      "Epoch 809/1000\n",
      "80/80 [==============================] - 0s 440us/sample - loss: 0.7324 - acc: 0.7750 - val_loss: 1.8748 - val_acc: 0.5000\n",
      "Epoch 810/1000\n",
      "80/80 [==============================] - 0s 446us/sample - loss: 0.7315 - acc: 0.7875 - val_loss: 1.8857 - val_acc: 0.5000\n",
      "Epoch 811/1000\n",
      "80/80 [==============================] - 0s 467us/sample - loss: 0.7316 - acc: 0.7750 - val_loss: 1.8651 - val_acc: 0.5000\n",
      "Epoch 812/1000\n",
      "80/80 [==============================] - 0s 433us/sample - loss: 0.7308 - acc: 0.7750 - val_loss: 1.8613 - val_acc: 0.5000\n",
      "Epoch 813/1000\n",
      "80/80 [==============================] - 0s 497us/sample - loss: 0.7315 - acc: 0.8000 - val_loss: 1.8799 - val_acc: 0.5000\n",
      "Epoch 814/1000\n",
      "80/80 [==============================] - 0s 493us/sample - loss: 0.7294 - acc: 0.7875 - val_loss: 1.8869 - val_acc: 0.5000\n",
      "Epoch 815/1000\n",
      "80/80 [==============================] - 0s 446us/sample - loss: 0.7294 - acc: 0.7750 - val_loss: 1.8722 - val_acc: 0.5500\n",
      "Epoch 816/1000\n",
      "80/80 [==============================] - 0s 461us/sample - loss: 0.7302 - acc: 0.7750 - val_loss: 1.9415 - val_acc: 0.5500\n",
      "Epoch 817/1000\n",
      "80/80 [==============================] - 0s 463us/sample - loss: 0.7297 - acc: 0.8000 - val_loss: 1.8836 - val_acc: 0.5000\n",
      "Epoch 818/1000\n",
      "80/80 [==============================] - 0s 426us/sample - loss: 0.7278 - acc: 0.7750 - val_loss: 1.9017 - val_acc: 0.5000\n",
      "Epoch 819/1000\n",
      "80/80 [==============================] - 0s 512us/sample - loss: 0.7277 - acc: 0.7750 - val_loss: 1.8796 - val_acc: 0.5000\n",
      "Epoch 820/1000\n",
      "80/80 [==============================] - 0s 445us/sample - loss: 0.7277 - acc: 0.7750 - val_loss: 1.8825 - val_acc: 0.5000\n",
      "Epoch 821/1000\n",
      "80/80 [==============================] - 0s 459us/sample - loss: 0.7276 - acc: 0.7875 - val_loss: 1.8928 - val_acc: 0.5500\n",
      "Epoch 822/1000\n",
      "80/80 [==============================] - 0s 446us/sample - loss: 0.7271 - acc: 0.7875 - val_loss: 1.8913 - val_acc: 0.5000\n",
      "Epoch 823/1000\n",
      "80/80 [==============================] - 0s 492us/sample - loss: 0.7264 - acc: 0.7875 - val_loss: 1.8975 - val_acc: 0.5500\n",
      "Epoch 824/1000\n",
      "80/80 [==============================] - 0s 412us/sample - loss: 0.7272 - acc: 0.7750 - val_loss: 1.9126 - val_acc: 0.5000\n",
      "Epoch 825/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 0.7254 - acc: 0.7875 - val_loss: 1.9206 - val_acc: 0.5000\n",
      "Epoch 826/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 0.7260 - acc: 0.7875 - val_loss: 1.9088 - val_acc: 0.5000\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 459us/sample - loss: 0.7239 - acc: 0.7750 - val_loss: 1.9088 - val_acc: 0.5000\n",
      "Epoch 828/1000\n",
      "80/80 [==============================] - 0s 417us/sample - loss: 0.7237 - acc: 0.7750 - val_loss: 1.9301 - val_acc: 0.5000\n",
      "Epoch 829/1000\n",
      "80/80 [==============================] - 0s 443us/sample - loss: 0.7233 - acc: 0.7875 - val_loss: 1.8985 - val_acc: 0.5000\n",
      "Epoch 830/1000\n",
      "80/80 [==============================] - 0s 564us/sample - loss: 0.7240 - acc: 0.7875 - val_loss: 1.9194 - val_acc: 0.5000\n",
      "Epoch 831/1000\n",
      "80/80 [==============================] - 0s 444us/sample - loss: 0.7224 - acc: 0.7875 - val_loss: 1.9239 - val_acc: 0.5000\n",
      "Epoch 832/1000\n",
      "80/80 [==============================] - 0s 434us/sample - loss: 0.7231 - acc: 0.7750 - val_loss: 1.8841 - val_acc: 0.5000\n",
      "Epoch 833/1000\n",
      "80/80 [==============================] - 0s 453us/sample - loss: 0.7217 - acc: 0.7875 - val_loss: 1.8994 - val_acc: 0.5000\n",
      "Epoch 834/1000\n",
      "80/80 [==============================] - 0s 444us/sample - loss: 0.7227 - acc: 0.7875 - val_loss: 1.9389 - val_acc: 0.5000\n",
      "Epoch 835/1000\n",
      "80/80 [==============================] - 0s 445us/sample - loss: 0.7214 - acc: 0.7875 - val_loss: 1.9334 - val_acc: 0.5000\n",
      "Epoch 836/1000\n",
      "80/80 [==============================] - 0s 478us/sample - loss: 0.7217 - acc: 0.7750 - val_loss: 1.9122 - val_acc: 0.5000\n",
      "Epoch 837/1000\n",
      "80/80 [==============================] - 0s 443us/sample - loss: 0.7198 - acc: 0.7875 - val_loss: 1.9266 - val_acc: 0.5000\n",
      "Epoch 838/1000\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 0.7192 - acc: 0.7875 - val_loss: 1.9130 - val_acc: 0.5500\n",
      "Epoch 839/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 0.7195 - acc: 0.7875 - val_loss: 1.9281 - val_acc: 0.5000\n",
      "Epoch 840/1000\n",
      "80/80 [==============================] - 0s 401us/sample - loss: 0.7203 - acc: 0.8000 - val_loss: 1.9124 - val_acc: 0.5000\n",
      "Epoch 841/1000\n",
      "80/80 [==============================] - 0s 357us/sample - loss: 0.7183 - acc: 0.7875 - val_loss: 1.9268 - val_acc: 0.5000\n",
      "Epoch 842/1000\n",
      "80/80 [==============================] - 0s 422us/sample - loss: 0.7182 - acc: 0.7875 - val_loss: 1.9219 - val_acc: 0.5000\n",
      "Epoch 843/1000\n",
      "80/80 [==============================] - 0s 393us/sample - loss: 0.7183 - acc: 0.7875 - val_loss: 1.9214 - val_acc: 0.5000\n",
      "Epoch 844/1000\n",
      "80/80 [==============================] - 0s 427us/sample - loss: 0.7194 - acc: 0.7750 - val_loss: 1.9324 - val_acc: 0.5000\n",
      "Epoch 845/1000\n",
      "80/80 [==============================] - 0s 423us/sample - loss: 0.7171 - acc: 0.7875 - val_loss: 1.9181 - val_acc: 0.5000\n",
      "Epoch 846/1000\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 0.7175 - acc: 0.7875 - val_loss: 1.9208 - val_acc: 0.5000\n",
      "Epoch 847/1000\n",
      "80/80 [==============================] - 0s 415us/sample - loss: 0.7167 - acc: 0.7875 - val_loss: 1.9457 - val_acc: 0.5000\n",
      "Epoch 848/1000\n",
      "80/80 [==============================] - 0s 443us/sample - loss: 0.7153 - acc: 0.7875 - val_loss: 1.9209 - val_acc: 0.5000\n",
      "Epoch 849/1000\n",
      "80/80 [==============================] - 0s 403us/sample - loss: 0.7166 - acc: 0.7875 - val_loss: 1.9430 - val_acc: 0.5000\n",
      "Epoch 850/1000\n",
      "80/80 [==============================] - 0s 440us/sample - loss: 0.7148 - acc: 0.7875 - val_loss: 1.9588 - val_acc: 0.5000\n",
      "Epoch 851/1000\n",
      "80/80 [==============================] - 0s 438us/sample - loss: 0.7155 - acc: 0.7750 - val_loss: 1.9427 - val_acc: 0.5000\n",
      "Epoch 852/1000\n",
      "80/80 [==============================] - 0s 465us/sample - loss: 0.7139 - acc: 0.7875 - val_loss: 1.9361 - val_acc: 0.5000\n",
      "Epoch 853/1000\n",
      "80/80 [==============================] - 0s 383us/sample - loss: 0.7131 - acc: 0.7875 - val_loss: 1.9633 - val_acc: 0.5000\n",
      "Epoch 854/1000\n",
      "80/80 [==============================] - 0s 353us/sample - loss: 0.7138 - acc: 0.7750 - val_loss: 1.9551 - val_acc: 0.5000\n",
      "Epoch 855/1000\n",
      "80/80 [==============================] - 0s 366us/sample - loss: 0.7124 - acc: 0.7875 - val_loss: 1.9345 - val_acc: 0.5500\n",
      "Epoch 856/1000\n",
      "80/80 [==============================] - 0s 385us/sample - loss: 0.7132 - acc: 0.7875 - val_loss: 1.9727 - val_acc: 0.5000\n",
      "Epoch 857/1000\n",
      "80/80 [==============================] - 0s 419us/sample - loss: 0.7118 - acc: 0.7875 - val_loss: 1.9527 - val_acc: 0.5000\n",
      "Epoch 858/1000\n",
      "80/80 [==============================] - 0s 364us/sample - loss: 0.7120 - acc: 0.7875 - val_loss: 1.9448 - val_acc: 0.5000\n",
      "Epoch 859/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 0.7116 - acc: 0.7875 - val_loss: 1.9336 - val_acc: 0.5500\n",
      "Epoch 860/1000\n",
      "80/80 [==============================] - 0s 519us/sample - loss: 0.7116 - acc: 0.7875 - val_loss: 1.9624 - val_acc: 0.5000\n",
      "Epoch 861/1000\n",
      "80/80 [==============================] - 0s 385us/sample - loss: 0.7108 - acc: 0.7875 - val_loss: 1.9568 - val_acc: 0.5000\n",
      "Epoch 862/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 0.7102 - acc: 0.7875 - val_loss: 1.9611 - val_acc: 0.5000\n",
      "Epoch 863/1000\n",
      "80/80 [==============================] - 0s 451us/sample - loss: 0.7102 - acc: 0.7875 - val_loss: 1.9722 - val_acc: 0.5000\n",
      "Epoch 864/1000\n",
      "80/80 [==============================] - 0s 516us/sample - loss: 0.7099 - acc: 0.7875 - val_loss: 1.9793 - val_acc: 0.5000\n",
      "Epoch 865/1000\n",
      "80/80 [==============================] - 0s 387us/sample - loss: 0.7088 - acc: 0.7875 - val_loss: 1.9668 - val_acc: 0.5000\n",
      "Epoch 866/1000\n",
      "80/80 [==============================] - 0s 389us/sample - loss: 0.7097 - acc: 0.7875 - val_loss: 1.9528 - val_acc: 0.5000\n",
      "Epoch 867/1000\n",
      "80/80 [==============================] - 0s 364us/sample - loss: 0.7090 - acc: 0.7875 - val_loss: 1.9643 - val_acc: 0.5000\n",
      "Epoch 868/1000\n",
      "80/80 [==============================] - 0s 381us/sample - loss: 0.7082 - acc: 0.7750 - val_loss: 1.9760 - val_acc: 0.5000\n",
      "Epoch 869/1000\n",
      "80/80 [==============================] - 0s 382us/sample - loss: 0.7091 - acc: 0.7875 - val_loss: 1.9710 - val_acc: 0.5000\n",
      "Epoch 870/1000\n",
      "80/80 [==============================] - 0s 367us/sample - loss: 0.7075 - acc: 0.7875 - val_loss: 1.9732 - val_acc: 0.5000\n",
      "Epoch 871/1000\n",
      "80/80 [==============================] - 0s 397us/sample - loss: 0.7075 - acc: 0.7875 - val_loss: 1.9644 - val_acc: 0.5000\n",
      "Epoch 872/1000\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 0.7072 - acc: 0.7875 - val_loss: 1.9810 - val_acc: 0.5000\n",
      "Epoch 873/1000\n",
      "80/80 [==============================] - 0s 359us/sample - loss: 0.7060 - acc: 0.7875 - val_loss: 1.9889 - val_acc: 0.5000\n",
      "Epoch 874/1000\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 0.7054 - acc: 0.7875 - val_loss: 1.9639 - val_acc: 0.5000\n",
      "Epoch 875/1000\n",
      "80/80 [==============================] - 0s 400us/sample - loss: 0.7056 - acc: 0.7875 - val_loss: 1.9744 - val_acc: 0.5000\n",
      "Epoch 876/1000\n",
      "80/80 [==============================] - 0s 397us/sample - loss: 0.7049 - acc: 0.7875 - val_loss: 1.9599 - val_acc: 0.5500\n",
      "Epoch 877/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 0.7046 - acc: 0.7875 - val_loss: 1.9970 - val_acc: 0.5000\n",
      "Epoch 878/1000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 0.7058 - acc: 0.7875 - val_loss: 1.9727 - val_acc: 0.5000\n",
      "Epoch 879/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 0.7040 - acc: 0.7875 - val_loss: 2.0005 - val_acc: 0.5000\n",
      "Epoch 880/1000\n",
      "80/80 [==============================] - 0s 367us/sample - loss: 0.7036 - acc: 0.7875 - val_loss: 1.9904 - val_acc: 0.5000\n",
      "Epoch 881/1000\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.7032 - acc: 0.7875 - val_loss: 1.9802 - val_acc: 0.5000\n",
      "Epoch 882/1000\n",
      "80/80 [==============================] - 0s 433us/sample - loss: 0.7031 - acc: 0.7875 - val_loss: 1.9856 - val_acc: 0.5000\n",
      "Epoch 883/1000\n",
      "80/80 [==============================] - 0s 434us/sample - loss: 0.7025 - acc: 0.7875 - val_loss: 2.0159 - val_acc: 0.5000\n",
      "Epoch 884/1000\n",
      "80/80 [==============================] - 0s 357us/sample - loss: 0.7032 - acc: 0.7875 - val_loss: 2.0133 - val_acc: 0.5000\n",
      "Epoch 885/1000\n",
      "80/80 [==============================] - 0s 388us/sample - loss: 0.7016 - acc: 0.7875 - val_loss: 1.9929 - val_acc: 0.5000\n",
      "Epoch 886/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 400us/sample - loss: 0.7010 - acc: 0.7875 - val_loss: 1.9904 - val_acc: 0.5500\n",
      "Epoch 887/1000\n",
      "80/80 [==============================] - 0s 356us/sample - loss: 0.7014 - acc: 0.7875 - val_loss: 2.0153 - val_acc: 0.5000\n",
      "Epoch 888/1000\n",
      "80/80 [==============================] - 0s 375us/sample - loss: 0.7013 - acc: 0.8000 - val_loss: 1.9942 - val_acc: 0.5000\n",
      "Epoch 889/1000\n",
      "80/80 [==============================] - 0s 397us/sample - loss: 0.7006 - acc: 0.8000 - val_loss: 2.0032 - val_acc: 0.5000\n",
      "Epoch 890/1000\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 0.7002 - acc: 0.7875 - val_loss: 1.9759 - val_acc: 0.5000\n",
      "Epoch 891/1000\n",
      "80/80 [==============================] - 0s 401us/sample - loss: 0.7008 - acc: 0.7875 - val_loss: 2.0168 - val_acc: 0.5000\n",
      "Epoch 892/1000\n",
      "80/80 [==============================] - 0s 357us/sample - loss: 0.6996 - acc: 0.8000 - val_loss: 1.9951 - val_acc: 0.5000\n",
      "Epoch 893/1000\n",
      "80/80 [==============================] - 0s 414us/sample - loss: 0.7000 - acc: 0.7875 - val_loss: 2.0105 - val_acc: 0.5000\n",
      "Epoch 894/1000\n",
      "80/80 [==============================] - 0s 350us/sample - loss: 0.6996 - acc: 0.7875 - val_loss: 2.0153 - val_acc: 0.5000\n",
      "Epoch 895/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 0.6981 - acc: 0.8000 - val_loss: 2.0023 - val_acc: 0.5000\n",
      "Epoch 896/1000\n",
      "80/80 [==============================] - 0s 395us/sample - loss: 0.6976 - acc: 0.8000 - val_loss: 2.0106 - val_acc: 0.5000\n",
      "Epoch 897/1000\n",
      "80/80 [==============================] - 0s 417us/sample - loss: 0.6971 - acc: 0.7875 - val_loss: 1.9887 - val_acc: 0.5500\n",
      "Epoch 898/1000\n",
      "80/80 [==============================] - 0s 409us/sample - loss: 0.6978 - acc: 0.7875 - val_loss: 2.0013 - val_acc: 0.5000\n",
      "Epoch 899/1000\n",
      "80/80 [==============================] - 0s 390us/sample - loss: 0.6965 - acc: 0.7875 - val_loss: 2.0316 - val_acc: 0.5000\n",
      "Epoch 900/1000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 0.6969 - acc: 0.7875 - val_loss: 2.0215 - val_acc: 0.5000\n",
      "Epoch 901/1000\n",
      "80/80 [==============================] - 0s 460us/sample - loss: 0.6959 - acc: 0.7875 - val_loss: 2.0247 - val_acc: 0.5000\n",
      "Epoch 902/1000\n",
      "80/80 [==============================] - 0s 428us/sample - loss: 0.6958 - acc: 0.8000 - val_loss: 2.0297 - val_acc: 0.5000\n",
      "Epoch 903/1000\n",
      "80/80 [==============================] - 0s 375us/sample - loss: 0.6955 - acc: 0.7875 - val_loss: 2.0140 - val_acc: 0.5000\n",
      "Epoch 904/1000\n",
      "80/80 [==============================] - 0s 359us/sample - loss: 0.6951 - acc: 0.7875 - val_loss: 2.0152 - val_acc: 0.5000\n",
      "Epoch 905/1000\n",
      "80/80 [==============================] - 0s 407us/sample - loss: 0.6947 - acc: 0.7875 - val_loss: 2.0243 - val_acc: 0.5500\n",
      "Epoch 906/1000\n",
      "80/80 [==============================] - 0s 396us/sample - loss: 0.6953 - acc: 0.7875 - val_loss: 2.0222 - val_acc: 0.5000\n",
      "Epoch 907/1000\n",
      "80/80 [==============================] - 0s 428us/sample - loss: 0.6940 - acc: 0.8000 - val_loss: 2.0344 - val_acc: 0.5000\n",
      "Epoch 908/1000\n",
      "80/80 [==============================] - 0s 442us/sample - loss: 0.6929 - acc: 0.8000 - val_loss: 2.0227 - val_acc: 0.5000\n",
      "Epoch 909/1000\n",
      "80/80 [==============================] - 0s 405us/sample - loss: 0.6926 - acc: 0.8000 - val_loss: 2.0307 - val_acc: 0.5000\n",
      "Epoch 910/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 0.6928 - acc: 0.7875 - val_loss: 2.0389 - val_acc: 0.5000\n",
      "Epoch 911/1000\n",
      "80/80 [==============================] - 0s 432us/sample - loss: 0.6938 - acc: 0.8000 - val_loss: 2.0353 - val_acc: 0.5000\n",
      "Epoch 912/1000\n",
      "80/80 [==============================] - 0s 497us/sample - loss: 0.6919 - acc: 0.7875 - val_loss: 2.0080 - val_acc: 0.5500\n",
      "Epoch 913/1000\n",
      "80/80 [==============================] - 0s 491us/sample - loss: 0.6919 - acc: 0.8000 - val_loss: 2.0581 - val_acc: 0.5000\n",
      "Epoch 914/1000\n",
      "80/80 [==============================] - 0s 438us/sample - loss: 0.6913 - acc: 0.7875 - val_loss: 2.0326 - val_acc: 0.5000\n",
      "Epoch 915/1000\n",
      "80/80 [==============================] - 0s 400us/sample - loss: 0.6920 - acc: 0.8000 - val_loss: 2.0406 - val_acc: 0.5000\n",
      "Epoch 916/1000\n",
      "80/80 [==============================] - 0s 359us/sample - loss: 0.6914 - acc: 0.8000 - val_loss: 2.0407 - val_acc: 0.5000\n",
      "Epoch 917/1000\n",
      "80/80 [==============================] - 0s 338us/sample - loss: 0.6900 - acc: 0.8000 - val_loss: 2.0347 - val_acc: 0.5500\n",
      "Epoch 918/1000\n",
      "80/80 [==============================] - 0s 314us/sample - loss: 0.6891 - acc: 0.8000 - val_loss: 2.0637 - val_acc: 0.5000\n",
      "Epoch 919/1000\n",
      "80/80 [==============================] - 0s 337us/sample - loss: 0.6900 - acc: 0.8000 - val_loss: 2.0515 - val_acc: 0.5000\n",
      "Epoch 920/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 0.6892 - acc: 0.8000 - val_loss: 2.0414 - val_acc: 0.5000\n",
      "Epoch 921/1000\n",
      "80/80 [==============================] - 0s 384us/sample - loss: 0.6889 - acc: 0.8000 - val_loss: 2.0233 - val_acc: 0.5500\n",
      "Epoch 922/1000\n",
      "80/80 [==============================] - 0s 353us/sample - loss: 0.6887 - acc: 0.8000 - val_loss: 2.0216 - val_acc: 0.5500\n",
      "Epoch 923/1000\n",
      "80/80 [==============================] - 0s 362us/sample - loss: 0.6894 - acc: 0.8000 - val_loss: 2.0277 - val_acc: 0.5000\n",
      "Epoch 924/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 0.6886 - acc: 0.8000 - val_loss: 2.0567 - val_acc: 0.5000\n",
      "Epoch 925/1000\n",
      "80/80 [==============================] - 0s 371us/sample - loss: 0.6881 - acc: 0.8000 - val_loss: 2.0658 - val_acc: 0.5000\n",
      "Epoch 926/1000\n",
      "80/80 [==============================] - 0s 352us/sample - loss: 0.6871 - acc: 0.8000 - val_loss: 2.0676 - val_acc: 0.5000\n",
      "Epoch 927/1000\n",
      "80/80 [==============================] - 0s 408us/sample - loss: 0.6870 - acc: 0.8000 - val_loss: 2.0514 - val_acc: 0.5000\n",
      "Epoch 928/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 0.6864 - acc: 0.8000 - val_loss: 2.0381 - val_acc: 0.5000\n",
      "Epoch 929/1000\n",
      "80/80 [==============================] - 0s 361us/sample - loss: 0.6860 - acc: 0.8000 - val_loss: 2.0550 - val_acc: 0.5500\n",
      "Epoch 930/1000\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 0.6855 - acc: 0.8000 - val_loss: 2.0590 - val_acc: 0.5000\n",
      "Epoch 931/1000\n",
      "80/80 [==============================] - 0s 386us/sample - loss: 0.6851 - acc: 0.8000 - val_loss: 2.0831 - val_acc: 0.5000\n",
      "Epoch 932/1000\n",
      "80/80 [==============================] - 0s 394us/sample - loss: 0.6850 - acc: 0.8000 - val_loss: 2.0938 - val_acc: 0.5000\n",
      "Epoch 933/1000\n",
      "80/80 [==============================] - 0s 339us/sample - loss: 0.6852 - acc: 0.8000 - val_loss: 2.0926 - val_acc: 0.5000\n",
      "Epoch 934/1000\n",
      "80/80 [==============================] - 0s 399us/sample - loss: 0.6846 - acc: 0.8000 - val_loss: 2.0571 - val_acc: 0.5000\n",
      "Epoch 935/1000\n",
      "80/80 [==============================] - 0s 368us/sample - loss: 0.6842 - acc: 0.8000 - val_loss: 2.0509 - val_acc: 0.5500\n",
      "Epoch 936/1000\n",
      "80/80 [==============================] - 0s 367us/sample - loss: 0.6842 - acc: 0.7875 - val_loss: 2.0933 - val_acc: 0.5000\n",
      "Epoch 937/1000\n",
      "80/80 [==============================] - 0s 356us/sample - loss: 0.6840 - acc: 0.8000 - val_loss: 2.0687 - val_acc: 0.5500\n",
      "Epoch 938/1000\n",
      "80/80 [==============================] - 0s 408us/sample - loss: 0.6829 - acc: 0.7875 - val_loss: 2.0753 - val_acc: 0.5000\n",
      "Epoch 939/1000\n",
      "80/80 [==============================] - 0s 430us/sample - loss: 0.6830 - acc: 0.8000 - val_loss: 2.0782 - val_acc: 0.5000\n",
      "Epoch 940/1000\n",
      "80/80 [==============================] - 0s 464us/sample - loss: 0.6820 - acc: 0.8000 - val_loss: 2.0819 - val_acc: 0.5000\n",
      "Epoch 941/1000\n",
      "80/80 [==============================] - 0s 404us/sample - loss: 0.6822 - acc: 0.8000 - val_loss: 2.0872 - val_acc: 0.5000\n",
      "Epoch 942/1000\n",
      "80/80 [==============================] - 0s 469us/sample - loss: 0.6820 - acc: 0.8000 - val_loss: 2.0735 - val_acc: 0.5000\n",
      "Epoch 943/1000\n",
      "80/80 [==============================] - 0s 441us/sample - loss: 0.6816 - acc: 0.8000 - val_loss: 2.0676 - val_acc: 0.5500\n",
      "Epoch 944/1000\n",
      "80/80 [==============================] - 0s 370us/sample - loss: 0.6817 - acc: 0.8000 - val_loss: 2.0593 - val_acc: 0.5500\n",
      "Epoch 945/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 370us/sample - loss: 0.6813 - acc: 0.8000 - val_loss: 2.0654 - val_acc: 0.5000\n",
      "Epoch 946/1000\n",
      "80/80 [==============================] - 0s 351us/sample - loss: 0.6804 - acc: 0.8000 - val_loss: 2.0600 - val_acc: 0.5500\n",
      "Epoch 947/1000\n",
      "80/80 [==============================] - 0s 347us/sample - loss: 0.6799 - acc: 0.8000 - val_loss: 2.0693 - val_acc: 0.5500\n",
      "Epoch 948/1000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.6798 - acc: 0.8000 - val_loss: 2.0850 - val_acc: 0.5000\n",
      "Epoch 949/1000\n",
      "80/80 [==============================] - 0s 311us/sample - loss: 0.6803 - acc: 0.8000 - val_loss: 2.1081 - val_acc: 0.5000\n",
      "Epoch 950/1000\n",
      "80/80 [==============================] - 0s 345us/sample - loss: 0.6788 - acc: 0.8000 - val_loss: 2.0818 - val_acc: 0.5500\n",
      "Epoch 951/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.6789 - acc: 0.8000 - val_loss: 2.1126 - val_acc: 0.5000\n",
      "Epoch 952/1000\n",
      "80/80 [==============================] - 0s 278us/sample - loss: 0.6789 - acc: 0.8000 - val_loss: 2.0736 - val_acc: 0.5500\n",
      "Epoch 953/1000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 0.6785 - acc: 0.8000 - val_loss: 2.0800 - val_acc: 0.5500\n",
      "Epoch 954/1000\n",
      "80/80 [==============================] - 0s 292us/sample - loss: 0.6778 - acc: 0.8000 - val_loss: 2.1296 - val_acc: 0.5000\n",
      "Epoch 955/1000\n",
      "80/80 [==============================] - 0s 328us/sample - loss: 0.6779 - acc: 0.8000 - val_loss: 2.1032 - val_acc: 0.5000\n",
      "Epoch 956/1000\n",
      "80/80 [==============================] - 0s 295us/sample - loss: 0.6773 - acc: 0.8000 - val_loss: 2.1115 - val_acc: 0.5000\n",
      "Epoch 957/1000\n",
      "80/80 [==============================] - 0s 374us/sample - loss: 0.6768 - acc: 0.8000 - val_loss: 2.1118 - val_acc: 0.5000\n",
      "Epoch 958/1000\n",
      "80/80 [==============================] - 0s 285us/sample - loss: 0.6764 - acc: 0.8000 - val_loss: 2.1059 - val_acc: 0.5000\n",
      "Epoch 959/1000\n",
      "80/80 [==============================] - 0s 284us/sample - loss: 0.6767 - acc: 0.8000 - val_loss: 2.1028 - val_acc: 0.5500\n",
      "Epoch 960/1000\n",
      "80/80 [==============================] - 0s 302us/sample - loss: 0.6775 - acc: 0.8000 - val_loss: 2.0924 - val_acc: 0.5000\n",
      "Epoch 961/1000\n",
      "80/80 [==============================] - 0s 321us/sample - loss: 0.6753 - acc: 0.8000 - val_loss: 2.1077 - val_acc: 0.5000\n",
      "Epoch 962/1000\n",
      "80/80 [==============================] - 0s 352us/sample - loss: 0.6749 - acc: 0.8000 - val_loss: 2.1271 - val_acc: 0.5000\n",
      "Epoch 963/1000\n",
      "80/80 [==============================] - 0s 292us/sample - loss: 0.6764 - acc: 0.8000 - val_loss: 2.1036 - val_acc: 0.5000\n",
      "Epoch 964/1000\n",
      "80/80 [==============================] - 0s 284us/sample - loss: 0.6747 - acc: 0.8000 - val_loss: 2.1298 - val_acc: 0.5000\n",
      "Epoch 965/1000\n",
      "80/80 [==============================] - 0s 313us/sample - loss: 0.6745 - acc: 0.8000 - val_loss: 2.1223 - val_acc: 0.5000\n",
      "Epoch 966/1000\n",
      "80/80 [==============================] - 0s 312us/sample - loss: 0.6745 - acc: 0.8000 - val_loss: 2.1101 - val_acc: 0.5000\n",
      "Epoch 967/1000\n",
      "80/80 [==============================] - 0s 279us/sample - loss: 0.6732 - acc: 0.8000 - val_loss: 2.1331 - val_acc: 0.5000\n",
      "Epoch 968/1000\n",
      "80/80 [==============================] - 0s 271us/sample - loss: 0.6744 - acc: 0.8000 - val_loss: 2.1272 - val_acc: 0.5000\n",
      "Epoch 969/1000\n",
      "80/80 [==============================] - 0s 338us/sample - loss: 0.6737 - acc: 0.8000 - val_loss: 2.1057 - val_acc: 0.5500\n",
      "Epoch 970/1000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 0.6732 - acc: 0.7875 - val_loss: 2.1102 - val_acc: 0.5000\n",
      "Epoch 971/1000\n",
      "80/80 [==============================] - 0s 294us/sample - loss: 0.6727 - acc: 0.8000 - val_loss: 2.1194 - val_acc: 0.5500\n",
      "Epoch 972/1000\n",
      "80/80 [==============================] - 0s 339us/sample - loss: 0.6720 - acc: 0.8000 - val_loss: 2.0984 - val_acc: 0.5500\n",
      "Epoch 973/1000\n",
      "80/80 [==============================] - 0s 337us/sample - loss: 0.6723 - acc: 0.8000 - val_loss: 2.1416 - val_acc: 0.5000\n",
      "Epoch 974/1000\n",
      "80/80 [==============================] - 0s 299us/sample - loss: 0.6714 - acc: 0.8000 - val_loss: 2.1181 - val_acc: 0.5000\n",
      "Epoch 975/1000\n",
      "80/80 [==============================] - 0s 328us/sample - loss: 0.6710 - acc: 0.8000 - val_loss: 2.1301 - val_acc: 0.5000\n",
      "Epoch 976/1000\n",
      "80/80 [==============================] - 0s 287us/sample - loss: 0.6714 - acc: 0.8000 - val_loss: 2.1235 - val_acc: 0.5500\n",
      "Epoch 977/1000\n",
      "80/80 [==============================] - 0s 311us/sample - loss: 0.6712 - acc: 0.8000 - val_loss: 2.1380 - val_acc: 0.5500\n",
      "Epoch 978/1000\n",
      "80/80 [==============================] - 0s 314us/sample - loss: 0.6703 - acc: 0.8000 - val_loss: 2.1570 - val_acc: 0.5000\n",
      "Epoch 979/1000\n",
      "80/80 [==============================] - 0s 266us/sample - loss: 0.6702 - acc: 0.8000 - val_loss: 2.1292 - val_acc: 0.5500\n",
      "Epoch 980/1000\n",
      "80/80 [==============================] - 0s 282us/sample - loss: 0.6693 - acc: 0.8000 - val_loss: 2.1674 - val_acc: 0.5000\n",
      "Epoch 981/1000\n",
      "80/80 [==============================] - 0s 298us/sample - loss: 0.6698 - acc: 0.8000 - val_loss: 2.1298 - val_acc: 0.5000\n",
      "Epoch 982/1000\n",
      "80/80 [==============================] - 0s 295us/sample - loss: 0.6691 - acc: 0.8000 - val_loss: 2.1427 - val_acc: 0.5000\n",
      "Epoch 983/1000\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 0.6696 - acc: 0.8000 - val_loss: 2.1459 - val_acc: 0.5000\n",
      "Epoch 984/1000\n",
      "80/80 [==============================] - 0s 311us/sample - loss: 0.6697 - acc: 0.8000 - val_loss: 2.1320 - val_acc: 0.5000\n",
      "Epoch 985/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.6683 - acc: 0.8000 - val_loss: 2.1472 - val_acc: 0.5500\n",
      "Epoch 986/1000\n",
      "80/80 [==============================] - 0s 330us/sample - loss: 0.6678 - acc: 0.8000 - val_loss: 2.1364 - val_acc: 0.5500\n",
      "Epoch 987/1000\n",
      "80/80 [==============================] - 0s 328us/sample - loss: 0.6687 - acc: 0.8000 - val_loss: 2.1481 - val_acc: 0.5000\n",
      "Epoch 988/1000\n",
      "80/80 [==============================] - 0s 304us/sample - loss: 0.6667 - acc: 0.8000 - val_loss: 2.1127 - val_acc: 0.5500\n",
      "Epoch 989/1000\n",
      "80/80 [==============================] - 0s 356us/sample - loss: 0.6676 - acc: 0.8000 - val_loss: 2.1348 - val_acc: 0.5000\n",
      "Epoch 990/1000\n",
      "80/80 [==============================] - 0s 280us/sample - loss: 0.6672 - acc: 0.8000 - val_loss: 2.1429 - val_acc: 0.5000\n",
      "Epoch 991/1000\n",
      "80/80 [==============================] - 0s 300us/sample - loss: 0.6665 - acc: 0.8000 - val_loss: 2.1488 - val_acc: 0.5500\n",
      "Epoch 992/1000\n",
      "80/80 [==============================] - 0s 320us/sample - loss: 0.6667 - acc: 0.8000 - val_loss: 2.1366 - val_acc: 0.5000\n",
      "Epoch 993/1000\n",
      "80/80 [==============================] - 0s 320us/sample - loss: 0.6660 - acc: 0.8000 - val_loss: 2.1427 - val_acc: 0.5000\n",
      "Epoch 994/1000\n",
      "80/80 [==============================] - 0s 276us/sample - loss: 0.6658 - acc: 0.8000 - val_loss: 2.1705 - val_acc: 0.5000\n",
      "Epoch 995/1000\n",
      "80/80 [==============================] - 0s 323us/sample - loss: 0.6647 - acc: 0.8000 - val_loss: 2.1420 - val_acc: 0.5000\n",
      "Epoch 996/1000\n",
      "80/80 [==============================] - 0s 325us/sample - loss: 0.6646 - acc: 0.8000 - val_loss: 2.1789 - val_acc: 0.5000\n",
      "Epoch 997/1000\n",
      "80/80 [==============================] - 0s 331us/sample - loss: 0.6664 - acc: 0.8000 - val_loss: 2.1649 - val_acc: 0.5000\n",
      "Epoch 998/1000\n",
      "80/80 [==============================] - 0s 308us/sample - loss: 0.6646 - acc: 0.8000 - val_loss: 2.1624 - val_acc: 0.5500\n",
      "Epoch 999/1000\n",
      "80/80 [==============================] - 0s 332us/sample - loss: 0.6643 - acc: 0.8000 - val_loss: 2.1849 - val_acc: 0.5000\n",
      "Epoch 1000/1000\n",
      "80/80 [==============================] - 0s 303us/sample - loss: 0.6636 - acc: 0.8000 - val_loss: 2.1837 - val_acc: 0.5000\n",
      "10000/10000 [==============================] - 2s 159us/sample - loss: 2.1169 - acc: 0.4223\n",
      "Test loss: 2.116917222201824\n",
      "Test accuracy: 0.4223\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Source:https://gatech.instructure.com/courses/62736/files/folder/Advanced%20DNN%20Software%20%26%20Tools\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "train_rand_idxs = np.random.choice(50000, 80)\n",
    "val_rand_idxs = np.random.choice(10000, 20)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_val = to_categorical(Y_val)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, batch_size=10)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
